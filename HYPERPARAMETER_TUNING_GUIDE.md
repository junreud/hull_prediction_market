# 🎯 하이퍼파라미터 튜닝 가이드

**작성일**: 2025-11-18  
**목적**: Return 모델 튜닝 시 어떤 목표 함수를 사용할지 가이드

---

## 📊 4가지 튜닝 옵션

### 1. **`objective_type='combined'`** ⭐ **추천!**

**설명**: IC와 Spread를 동시에 최적화

**목표 함수**:
```python
combined_score = IC + (Spread × 100)
```

**장점**:
- ✅ 대회 점수와 가장 관련 높음
- ✅ 순위 예측력(IC)과 수익성(Spread) 동시 개선
- ✅ 한 번의 튜닝으로 최적화
- ✅ 실전에서 가장 좋은 성능

**단점**:
- ⚠️ 튜닝 시간이 RMSE보다 약간 느림 (20~30% 정도)

**언제 사용**:
- **기본 선택** (대부분의 경우)
- 대회 점수 직접 최적화 원할 때
- IC와 Spread 둘 다 중요할 때

**예상 소요 시간** (n_trials=50):
- 약 3~4시간

---

### 4. **`objective_type='rmse'`**

**설명**: 전통적인 RMSE 최소화

**목표 함수**:
```python
minimize RMSE
```

**장점**:
- ✅ 가장 빠름
- ✅ 안정적으로 수렴

**단점**:
- ❌ 대회 점수와 직접 관련 없음
- ❌ IC/Spread 개선 보장 안 됨
- ❌ 실전 성능 예측 어려움

**언제 사용**:
- 빠른 프로토타이핑
- 기본 베이스라인 구축
- 시간이 매우 제한적일 때

**예상 소요 시간** (n_trials=50):
- 약 2~3시간

---

## 🚀 사용 방법

### 방법 1: 스크립트 실행

```bash
# Combined 모드 (추천)
python scripts/optimize_return_model.py
```

기본값이 `objective_type='combined'`로 설정되어 있습니다.

---

### 방법 2: 파라미터 변경

`scripts/optimize_return_model.py` 파일의 마지막 부분:

```python
def main():
    optimizer = ReturnModelOptimizer(config_path="conf/params.yaml")
    
    results = optimizer.run_full_optimization(
        # ... 다른 파라미터들 ...
        
        # 여기를 변경!
        objective_type='combined',  # ← 'rmse', 'ic', 'spread', 'combined' 중 선택
        n_trials=50,
    )
```

**옵션 변경 예시**:

```python
# IC만 최적화
objective_type='ic'

# Spread만 최적화
objective_type='spread'

# RMSE 최적화 (빠른 테스트용)
objective_type='rmse'
```

---

## 📊 결과 해석

### Combined 모드 실행 시:

```
================================================================================
Optimization Results
================================================================================

Best Score (Combined): 0.0892  ← 높을수록 좋음
  → IC: 0.0823  ← 정보 계수
  → Spread: 0.00069 (0.0690%)  ← Long-Short 수익률
Best Trial: 23

Best Parameters:
  num_leaves: 45
  learning_rate: 0.0234
  ...
```

**해석**:
- **Combined Score**: IC + (Spread × 100)
  - 0.08 이상: 좋음 ✅
  - 0.10 이상: 매우 좋음 🌟
  
- **IC**: 0.0823
  - > 0.05: 유의미 ✅
  - > 0.08: 우수 🌟
  
- **Spread**: 0.0690%
  - > 0.10%: 수익 가능 ✅
  - > 0.20%: 좋은 수익 🌟

---

## 🎯 추천 워크플로우

### Phase 1: 빠른 탐색 (1~2시간)
```python
objective_type='rmse'
n_trials=20
```
→ 기본 성능 확인

---

### Phase 2: 정밀 최적화 (3~4시간) ⭐ **메인**
```python
objective_type='combined'
n_trials=50
```
→ 최종 모델 생성

---

### Phase 3: 추가 개선 (선택, 3~4시간)
```python
objective_type='ic'  # 또는 'spread'
n_trials=50
```
→ 특정 지표 극대화

---

## 💡 FAQ

### Q1: Combined vs IC/Spread 따로 튜닝?

**A**: **Combined 한 번이면 충분!**

```python
# ❌ 비효율적
1. IC 기준 튜닝 (50 trials, 3시간)
2. Spread 기준 튜닝 (50 trials, 3시간)
→ 총 6시간, 어떤 결과 쓸지 애매

# ✅ 효율적
1. Combined 기준 튜닝 (50 trials, 3시간)
→ IC와 Spread 동시 최적화
```

---

### Q2: Combined의 가중치 조정?

**현재 설정**:
```python
combined_score = IC + (Spread × 100)
```

**변경하려면** (`src/tuner.py` 줄 256):
```python
# Spread 더 중요하게
combined_score = IC + (Spread × 200)  # Spread 2배 가중치

# IC 더 중요하게
combined_score = (IC × 2) + (Spread × 100)  # IC 2배 가중치
```

**기본 가중치가 적절한 이유**:
- IC 범위: 0 ~ 0.15
- Spread 범위: 0 ~ 0.003 (0.3%)
- Spread × 100 = 0 ~ 0.3 (IC와 비슷한 스케일)

---

### Q3: 왜 RMSE는 추천 안 하나요?

**핵심**: RMSE는 "절대값 예측 정확도"이지, "수익성 예측"이 아닙니다!

#### 📊 구체적 예시:

**모델 A (RMSE 최적화)**:
```
실제값:  [+0.015, +0.002, -0.008, +0.020, -0.003]
예측값:  [+0.014, +0.001, -0.007, +0.019, -0.002]
RMSE: 0.0010 ✅ (매우 낮음!)

하지만:
- 절대값은 잘 맞췄지만 순위 예측은 별로
- 상위 20% 예측: 4번째(+0.019) ✅, 1번째(+0.014) ✅
- 하위 20% 예측: 5번째(-0.002) ❌ (실제론 3번째가 최악)
```

**모델 B (IC/Spread 최적화)**:
```
실제값:  [+0.015, +0.002, -0.008, +0.020, -0.003]
예측값:  [+0.010, -0.001, -0.012, +0.025, -0.005]
RMSE: 0.0030 ⚠️ (3배 높음!)

하지만:
- 순위 예측은 완벽!
- 상위 20% 예측: 4번째(+0.025) ✅ → 실제 최고 수익
- 하위 20% 예측: 5번째(-0.005) ✅ → 실제 손실 방지
```

#### 💰 수익 계산:

**모델 A (RMSE=0.0010)**:
- Long: +0.019 + 0.014 = +3.3%
- Short: -0.002 = +0.2%
- **Spread: 3.5%** (운이 좋았음)

**모델 B (RMSE=0.0030)**:
- Long: +0.025 + 0.010 = +3.5%
- Short: -0.005 = +0.5%
- **Spread: 4.0%** ✅ (더 높음!)

#### 🎯 왜 이런 일이?

**RMSE는 "오차의 크기"만 본다**:
```python
# 실제: +0.020 (1등)
예측A: +0.019  → 오차: 0.001 ✅ (RMSE 좋음)
예측B: +0.025  → 오차: 0.005 ❌ (RMSE 나쁨)

# 하지만 순위는?
예측A: 2등으로 예측 (실제 1등)
예측B: 1등으로 예측 (실제 1등) ✅ 정확!
```

**IC/Spread는 "순위"를 본다**:
```python
# IC = 순위 상관계수
실제 순위: [2, 3, 4, 1, 5]
예측A 순위: [2, 3, 4, 1, 5]  → IC = 1.0 ✅
예측B 순위: [2, 4, 5, 1, 3]  → IC = 0.7 ⚠️

# 하지만 RMSE는?
예측A: 0.001 ✅
예측B: 0.003 (3배 나쁨)
```

#### 📈 실제 대회에서는?

**RMSE 튜닝**:
```
RMSE: 0.0105 ✅ (낮음!)
→ 절대값 예측은 정확
→ 하지만 순위가 뒤죽박죽

결과:
IC: 0.028 ❌ (거의 랜덤)
Spread: 0.047% ❌ (거래비용도 못 벌음)
대회 점수: 하위권
```

**Combined 튜닝**:
```
RMSE: 0.0115 ⚠️ (10% 높음)
→ 절대값은 조금 틀려도
→ 순위는 정확!

결과:
IC: 0.082 ✅ (우수한 순위 예측)
Spread: 0.18% ✅ (수익 가능)
대회 점수: 상위권
```

#### 🤔 왜 절대값 맞추면 순위가 틀리나?

**RMSE 최적화는 "큰 오차"를 줄이는 데 집중**:
```python
# 실제값
주식1: +0.030 (큰 상승)
주식2: +0.001 (소폭 상승)
주식3: -0.002 (소폭 하락)

# RMSE 최적화 모델
예측1: +0.025  → 오차 0.005 (큰 오차!)
예측2: +0.001  → 오차 0.000 ✅
예측3: -0.002  → 오차 0.000 ✅

→ 모델은 1번 오차를 줄이는데 집중
→ 2번과 3번을 완벽히 맞추면 RMSE 감소
→ 하지만 순위는?: 1>2>3 vs 1>2>3 (맞음)

# 만약 2번과 3번 순서가 바뀌면?
예측1: +0.025  → 오차 0.005
예측2: -0.001  → 오차 0.002 (작은 오차)
예측3: +0.002  → 오차 0.004 (작은 오차)

→ RMSE: 0.0040 (조금 나빠짐)
→ 하지만 순위: 1>3>2 (완전 틀림!)
```

**IC/Spread 최적화는 "순위"에 집중**:
```python
# 절대값이 조금 틀려도 순위만 맞으면 OK!
예측1: +0.035  → 오차 0.005 (큼)
예측2: +0.003  → 오차 0.002
예측3: -0.004  → 오차 0.002

→ RMSE: 0.0042 (높음)
→ 순위: 1>2>3 ✅ (완벽!)
→ IC: 1.0 ✅
→ Spread: (0.035) - (-0.004) = 3.9% ✅
```

---

**결론**: 
- RMSE ↓ = 수익률 **절대값** 잘 맞춤
- IC ↑ = 어떤 주식이 **상대적으로** 더 오를지 잘 맞춤 ⭐
- Spread ↑ = **수익성 있는** 예측 ⭐

**대회는 "절대값"이 아니라 "상대적 순위"를 평가!**

---

### Q4: 시간이 없을 땐?

**Option 1: trials 줄이기**
```python
n_trials=20  # 약 1.5시간
```

**Option 2: RMSE로 빠르게**
```python
objective_type='rmse'
n_trials=30  # 약 1.5시간
```

**Option 3: timeout 설정**
```python
timeout=3600  # 1시간 제한
```

---

## 📋 체크리스트

### 튜닝 전:
- [ ] 피처 엔지니어링 완료
- [ ] 피처 선택 완료 (200개 내외)
- [ ] 시간 여유 확보 (3~4시간)

### 튜닝 중:
- [ ] 로그 확인 (IC/Spread 개선되는지)
- [ ] Early stopping 작동 확인
- [ ] 메모리 사용량 체크

### 튜닝 후:
- [ ] IC > 0.05 달성
- [ ] Spread > 0.10% 달성
- [ ] Combined Score > 0.08 달성
- [ ] 모델 저장 확인 (`artifacts/`)

---

## ✅ 결론

### 추천 설정:

```python
# scripts/optimize_return_model.py
results = optimizer.run_full_optimization(
    # ... 다른 설정 ...
    
    # 하이퍼파라미터 튜닝
    n_trials=50,
    objective_type='combined',  # ⭐ 이게 최선!
)
```

### 이유:
1. IC와 Spread를 **동시에** 최적화
2. 대회 점수와 **직접 연결**
3. 한 번만 실행하면 됨
4. 가장 실전적인 결과

---

## ⚠️ 중요: Return 모델 vs Position 최적화의 차이

### 🤔 "순위만 맞으면 수익"이 무슨 뜻이지?

**잘못된 이해**:
```
IC/Spread만 높이면 끝? 
→ ❌ 아닙니다! 이건 Return 모델 평가일 뿐!
```

**올바른 이해 - 3단계 프로세스**:

#### 1️⃣ **Return 모델 학습** (이 가이드의 범위)
```python
# 목표: 수익률 예측 정확도 높이기
r_hat = model.predict(features)  # 예측 수익률

# 평가 지표:
- IC: 순위 상관계수 (예측 순위 vs 실제 순위)
- Spread: 상위 20% - 하위 20% 평균 수익

# 왜 순위가 중요?
→ Position 단계에서 "상위 N%"를 선택하기 때문
→ 절대값 맞추는 것보다 순위가 중요
```

#### 2️⃣ **Risk 모델 학습** (별도)
```python
# 목표: 변동성 예측
sigma_hat = risk_model.predict(features)  # 예측 변동성
```

#### 3️⃣ **Position 최적화** ⭐ **대회의 진짜 목표!**
```python
# 입력: r_hat (수익 예측), sigma_hat (리스크 예측)
# 출력: allocation (0~2, 얼마나 투자할지)

# 제약조건:
1. 급격한 변화 패널티 (큰 position 변동)
2. Volatility 패널티 (시장 대비 1.2배 초과 시)
3. Leverage 제한 (총 투자 비율)

# 최종 목표:
maximize Sharpe Ratio = mean(returns) / std(returns) / vol_penalty
```

---

### 📊 구체적 예시: 전체 프로세스

#### Day 1:
```python
# Step 1: Return 모델 예측
r_hat = [+0.02, +0.01, -0.01, +0.03, -0.02]  # 5개 주식 수익률 예측
IC = 0.8 (순위 잘 맞춤!)

# Step 2: Risk 모델 예측
sigma_hat = [0.05, 0.03, 0.02, 0.08, 0.04]  # 변동성 예측

# Step 3: Position 최적화
# 단순히 "상위 20% Long"이 아니라:
# - 수익/리스크 비율 고려
# - 이전 날 포지션 고려 (급변 방지)
# - 변동성 제약 고려

allocation_day1 = [0.8, 1.2, 0.5, 1.5, 0.3]
# 주식4(+0.03)가 제일 높지만 변동성(0.08)도 높아서 1.5만 투자
# 주식2(+0.01)는 안정적(0.03)해서 1.2 투자
```

#### Day 2:
```python
# Step 1: Return 모델 예측 (새로운 예측)
r_hat = [+0.01, +0.02, +0.03, -0.01, +0.01]
# 순위가 완전 바뀜!

# Step 2: Risk 모델 예측
sigma_hat = [0.04, 0.03, 0.06, 0.03, 0.05]

# Step 3: Position 최적화
# ⚠️ 여기서 급격한 변화 패널티!
# 만약 allocation을 [1.5, 0.5, 1.8, 0.2, 0.4]로 바꾸면?
# → Day1 대비 큰 변화 → 패널티!

# 최적화 결과:
allocation_day2 = [1.0, 1.1, 1.3, 0.4, 0.5]
# 점진적 변화로 패널티 최소화
```

---

### 💡 왜 이렇게 복잡하게?

**질문**: "그냥 r_hat 높은 곳에 투자하면 안 돼?"

**답변**: 안됩니다! 실제 대회 제약 때문에:

#### 문제 1: 급격한 Position 변화
```python
# Day 1: 주식A에 2.0 투자
# Day 2: 주식A 예측이 나빠짐 → 0.0으로 변경?
# → 매도 비용, 슬리피지, 거래 비용 발생
# → Sharpe Ratio 하락!

# 해결: 점진적 조정
# Day 2: 1.5로 줄임 (0.5만 매도)
# Day 3: 1.0으로 줄임
# Day 4: 0.5로 줄임
```

#### 문제 2: Volatility 패널티
```python
# 시장 변동성: 2%
# 전략 변동성: 3%
# Vol Ratio: 3% / 2% = 1.5 > 1.2 (임계값)

# 패널티: 1 + (1.5 - 1.2) = 1.3
# 최종 점수: Sharpe / 1.3 (30% 감소!)

# 해결: 변동성 높은 주식 줄이기
# 수익 예측 높아도, sigma_hat 높으면 allocation 줄임
```

---

### 🎯 Return 모델 튜닝의 진짜 의미

**IC/Spread 최적화**:
```python
# Return 모델이 하는 일:
"이 주식들 중에 어떤 게 더 오를까?" (순위 예측)

# IC = 0.08이면?
→ "순위를 잘 맞춤"
→ Position 최적화할 때 좋은 입력값 제공

# Spread = 0.18%면?
→ "상위 20%와 하위 20% 차이가 큼"
→ Long-Short 전략 유리
```

**하지만 최종 점수는 Position 최적화에서 결정!**
```python
# 좋은 Return 모델 (IC=0.08) + 나쁜 Position 최적화
→ 급격한 변화, 높은 변동성
→ Sharpe: 1.2 / 1.5(penalty) = 0.8 ❌

# 괜찮은 Return 모델 (IC=0.06) + 좋은 Position 최적화  
→ 안정적 변화, 낮은 변동성
→ Sharpe: 1.0 / 1.0(penalty) = 1.0 ✅
```

---

### ✅ 정리

1. **이 가이드는 "Return 모델 튜닝"만 다룸**
   - IC/Spread 최적화
   - 좋은 수익률 예측 만들기
   - Position 최적화의 "입력값" 생성

2. **실제 대회 점수는 "Position 최적화"에서 결정**
   - `scripts/optimize_position_strategy.py` (별도 스크립트)
   - r_hat + sigma_hat → allocation
   - 제약 조건 만족하며 Sharpe 최대화

3. **왜 IC/Spread로 튜닝?**
   - 좋은 순위 예측 = Position 최적화에 좋은 재료
   - RMSE 낮아도 순위 틀리면 = 나쁜 재료
   - 최종 요리(Sharpe)는 다음 단계에서!

**다음 단계**: Return 모델 튜닝 후 → Position 최적화 실행!

---

**작성자**: AI Assistant  
**최종 업데이트**: 2025-11-18  
**다음 액션**: 
1. `python scripts/optimize_return_model.py` (이 가이드)
2. `python scripts/optimize_position_strategy.py` (Position 최적화)
