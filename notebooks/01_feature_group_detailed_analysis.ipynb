{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“Š Feature Group Detailed Analysis\n",
    "## Hull Tactical Market Prediction - Phase 2\n",
    "\n",
    "**Date:** 2025-11-11\n",
    "\n",
    "**Objectives:**\n",
    "1. ëª¨ë“  Feature ê·¸ë£¹ë³„ ì‹œê³„ì—´ ë¶„ì„ (E, V, M, I, P, S, D)\n",
    "2. ê° Featureì˜ í†µê³„ì  íŠ¹ì„± íŒŒì•…\n",
    "3. Feature ê°„ ì‹œê°„ì— ë”°ë¥¸ íŒ¨í„´ ë¹„êµ\n",
    "4. ì´ìƒì¹˜ ë° íŠ¸ë Œë“œ íƒì§€\n",
    "5. ê·¸ë£¹ë³„ ë¹„êµ ë¶„ì„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Get project root\n",
    "notebook_dir = os.getcwd() if '__file__' not in dir() else os.path.dirname(os.path.abspath(__file__))\n",
    "project_root = os.path.dirname(notebook_dir) if 'notebooks' in notebook_dir else notebook_dir\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Statistical analysis\n",
    "from scipy import stats\n",
    "\n",
    "# Project utilities\n",
    "from src.data import DataLoader\n",
    "from src.utils import set_seed, load_config\n",
    "\n",
    "# Load configuration\n",
    "config_path = os.path.join(project_root, 'conf', 'params.yaml')\n",
    "config = load_config(config_path)\n",
    "set_seed(config['seed'])\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "# Plot settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (16, 6)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "print('âœ… Setup complete!')\n",
    "print(f'ðŸ“‹ Seed: {config[\"seed\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to project root\n",
    "os.chdir(project_root)\n",
    "print(f\"ðŸ“‚ Working directory: {os.getcwd()}\")\n",
    "\n",
    "# Initialize DataLoader\n",
    "loader = DataLoader()\n",
    "\n",
    "# Load data\n",
    "train_df, test_df = loader.load_data()\n",
    "\n",
    "print(f'\\nðŸ“¦ Data Shape:')\n",
    "print(f'  Train: {train_df.shape}')\n",
    "print(f'  Test: {test_df.shape}')\n",
    "print(f'\\nðŸ“… Date range: {train_df[\"date_id\"].min()} - {train_df[\"date_id\"].max()}')\n",
    "\n",
    "# Display feature groups\n",
    "print('\\nðŸ·ï¸ Feature Groups:')\n",
    "for group, features in loader.feature_groups.items():\n",
    "    print(f'  {group}: {len(features)} features')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions: plotting and statistics\n",
    "\n",
    "def plot_feature_timeseries(df, features, group_name, max_cols=4):\n",
    "    \"\"\"Plot time series for all features in a group.\n",
    "\n",
    "    df : DataFrame with 'date_id' and features\n",
    "    features : list of feature names\n",
    "    group_name : string\n",
    "    \"\"\"\n",
    "    if not features:\n",
    "        print(f\"No features found for {group_name} group\")\n",
    "        return\n",
    "\n",
    "    n_features = len(features)\n",
    "    n_cols = min(max_cols, n_features)\n",
    "    n_rows = (n_features + n_cols - 1) // n_cols\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 4 * n_rows))\n",
    "    if n_rows * n_cols == 1:\n",
    "        axes = np.array([axes])\n",
    "    axes = np.array(axes).reshape(-1)\n",
    "\n",
    "    for idx, feat in enumerate(features):\n",
    "        ax = axes[idx]\n",
    "        ax.plot(df['date_id'], df[feat], linewidth=0.8, alpha=0.8)\n",
    "        ax.set_title(f'{feat}', fontsize=10, fontweight='bold')\n",
    "        ax.set_xlabel('Date ID', fontsize=9)\n",
    "        ax.set_ylabel('Value', fontsize=9)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # Add small stat box\n",
    "        mean_val = df[feat].mean()\n",
    "        std_val = df[feat].std()\n",
    "        stats_text = f'Mean: {mean_val:.4f}\\nStd: {std_val:.4f}'\n",
    "        ax.text(0.02, 0.98, stats_text, transform=ax.transAxes,\n",
    "                verticalalignment='top', fontsize=8,\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "    # Hide unused axes\n",
    "    for j in range(n_features, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    plt.suptitle(f'{group_name} Group - Time Series ({n_features} features)', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_feature_statistics(df, features, group_name):\n",
    "    \"\"\"Return DataFrame with descriptive stats and moments for features.\"\"\"\n",
    "    from scipy import stats as scipy_stats\n",
    "    if not features:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    stats_rows = []\n",
    "    for feat in features:\n",
    "        s = df[feat]\n",
    "        valid = s.dropna()\n",
    "        row = {\n",
    "            'Feature': feat,\n",
    "            'Group': group_name,\n",
    "            'Count': int(valid.shape[0]),\n",
    "            'Missing': int(s.isna().sum()),\n",
    "            'Missing %': float(s.isna().sum() / max(1, len(s)) * 100),\n",
    "            'Mean': float(valid.mean()) if len(valid) else np.nan,\n",
    "            'Std': float(valid.std()) if len(valid) else np.nan,\n",
    "            'Min': float(valid.min()) if len(valid) else np.nan,\n",
    "            'Q25': float(valid.quantile(0.25)) if len(valid) else np.nan,\n",
    "            'Median': float(valid.median()) if len(valid) else np.nan,\n",
    "            'Q75': float(valid.quantile(0.75)) if len(valid) else np.nan,\n",
    "            'Max': float(valid.max()) if len(valid) else np.nan,\n",
    "            'Skewness': float(scipy_stats.skew(valid)) if len(valid) else np.nan,\n",
    "            'Kurtosis': float(scipy_stats.kurtosis(valid)) if len(valid) else np.nan\n",
    "        }\n",
    "        stats_rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(stats_rows)\n",
    "\n",
    "\n",
    "def plot_distribution_comparison(df, features, group_name, max_features=12):\n",
    "    \"\"\"Plot histograms for first max_features in the list.\"\"\"\n",
    "    if not features:\n",
    "        return\n",
    "    plot_feats = features[:max_features]\n",
    "    n = len(plot_feats)\n",
    "    cols = 4\n",
    "    rows = (n + cols - 1) // cols\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(16, 3 * rows))\n",
    "    axes = np.array(axes).reshape(-1)\n",
    "\n",
    "    for i, feat in enumerate(plot_feats):\n",
    "        ax = axes[i]\n",
    "        df[feat].dropna().hist(bins=50, ax=ax, alpha=0.7, edgecolor='black')\n",
    "        ax.set_title(feat, fontsize=10)\n",
    "        ax.set_xlabel('Value')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "    for j in range(n, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    plt.suptitle(f'{group_name} Group - Distribution (showing first {n} features)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print('âœ… Helper functions inserted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E Group analysis (Economic indicators)\n",
    "e_features = loader.feature_groups.get('E', [])\n",
    "print(f\"ðŸ“Š Analyzing E Group ({len(e_features)} features)\\n\")\n",
    "\n",
    "# Time series (date_id vs value)\n",
    "plot_feature_timeseries(train_df, e_features, 'E')\n",
    "\n",
    "# Distribution (first 12 features)\n",
    "plot_distribution_comparison(train_df, e_features, 'E')\n",
    "\n",
    "# Statistics table\n",
    "e_stats = get_feature_statistics(train_df, e_features, 'E')\n",
    "print('\\nðŸ“ˆ E Group Statistical Summary:')\n",
    "print('='*80)\n",
    "display(e_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V Group analysis (Volatility indicators)\n",
    "v_features = loader.feature_groups.get('V', [])\n",
    "print(f\"ðŸ“Š Analyzing V Group ({len(v_features)} features)\\n\")\n",
    "\n",
    "plot_feature_timeseries(train_df, v_features, 'V')\n",
    "plot_distribution_comparison(train_df, v_features, 'V')\n",
    "\n",
    "v_stats = get_feature_statistics(train_df, v_features, 'V')\n",
    "print('\\nðŸ“ˆ V Group Statistical Summary:')\n",
    "print('='*80)\n",
    "display(v_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M Group analysis (Market indicators)\n",
    "m_features = loader.feature_groups.get('M', [])\n",
    "print(f\"ðŸ“Š Analyzing M Group ({len(m_features)} features)\\n\")\n",
    "\n",
    "plot_feature_timeseries(train_df, m_features, 'M')\n",
    "plot_distribution_comparison(train_df, m_features, 'M')\n",
    "\n",
    "m_stats = get_feature_statistics(train_df, m_features, 'M')\n",
    "print('\\nðŸ“ˆ M Group Statistical Summary:')\n",
    "print('='*80)\n",
    "display(m_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P, S, D group analyses + cross-group aggregation, CV/missing analysis, and exports\n",
    "import os\n",
    "from IPython.display import display\n",
    "\n",
    "results_dir = os.path.join(os.getcwd(), 'results', 'feature_analysis')\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "group_vars = {}\n",
    "for grp in ['P', 'S', 'D']:\n",
    "    feats = loader.feature_groups.get(grp, [])\n",
    "    print(f\"\\nðŸ“Š Analyzing {grp} Group ({len(feats)} features)\\n\")\n",
    "    if len(feats) == 0:\n",
    "        print(f\" - No features found for group {grp}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Time-series and distribution plots\n",
    "    try:\n",
    "        plot_feature_timeseries(train_df, feats, grp)\n",
    "        plot_distribution_comparison(train_df, feats, grp)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: plotting for group {grp} failed: {e}\")\n",
    "\n",
    "    # Stats\n",
    "    stats = get_feature_statistics(train_df, feats, grp)\n",
    "    group_vars[f'{grp.lower()}_stats'] = stats\n",
    "    print('\\nðŸ“ˆ {grp} Group Statistical Summary:'.format(grp=grp))\n",
    "    display(stats)\n",
    "\n",
    "# Collect any existing per-group stats (e, v, m, i, p, s, d)\n",
    "parts = []\n",
    "for name in ['e_stats','v_stats','m_stats','i_stats','p_stats','s_stats','d_stats']:\n",
    "    if name in globals():\n",
    "        parts.append(globals()[name])\n",
    "\n",
    "if len(parts) == 0:\n",
    "    print('No group stats found to aggregate. Make sure group cells have been run at least once.')\n",
    "else:\n",
    "    all_stats = pd.concat(parts, axis=0)\n",
    "    # Ensure numeric columns\n",
    "    for col in ['Mean','Std']:\n",
    "        if col not in all_stats.columns:\n",
    "            all_stats[col] = np.nan\n",
    "\n",
    "    # Coefficient of Variation (cv)\n",
    "    all_stats['cv'] = all_stats.apply(lambda r: (r['Std'] / abs(r['Mean'])) if pd.notnull(r['Mean']) and abs(r['Mean'])>1e-9 else np.nan, axis=1)\n",
    "\n",
    "    # Group-level summary\n",
    "    group_summary = all_stats.groupby('Group').agg(\n",
    "        features=('Feature', 'count'),\n",
    "        missing_total=('Missing', 'sum'),\n",
    "        mean_of_means=('Mean', 'mean'),\n",
    "        mean_of_std=('Std', 'mean'),\n",
    "        mean_of_cv=('cv', 'mean'),\n",
    "        mean_of_skew=('Skewness', 'mean'),\n",
    "        mean_of_kurtosis=('Kurtosis', 'mean')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Missing-data ranking\n",
    "    missing_by_feature = all_stats[['Group','Missing']].sort_values('Missing', ascending=False)\n",
    "\n",
    "    # Save CSVs\n",
    "    all_stats_path = os.path.join(results_dir, 'all_feature_stats.csv')\n",
    "    group_summary_path = os.path.join(results_dir, 'group_summary.csv')\n",
    "    missing_path = os.path.join(results_dir, 'missing_by_feature.csv')\n",
    "\n",
    "    all_stats.to_csv(all_stats_path)\n",
    "    group_summary.to_csv(group_summary_path, index=False)\n",
    "    missing_by_feature.to_csv(missing_path, index=False)\n",
    "\n",
    "    print('\\nâœ… Aggregation complete â€” saved CSVs to:')\n",
    "    print(' -', all_stats_path)\n",
    "    print(' -', group_summary_path)\n",
    "    print(' -', missing_path)\n",
    "\n",
    "    display(group_summary)\n",
    "    print('\\nTop 20 features by missing values:')\n",
    "    display(missing_by_feature.head(20))\n",
    "\n",
    "print('\\nAll done. Run the notebook cells (or this final cell) in order to generate plots and exports.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
