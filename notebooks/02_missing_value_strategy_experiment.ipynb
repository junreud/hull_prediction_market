{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# ğŸ§ª Missing Value Strategy Experiment\n",
    "## ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì „ëµ ë¹„êµ ì‹¤í—˜\n",
    "\n",
    "**Date:** 2025-11-13\n",
    "\n",
    "**ëª©í‘œ:**\n",
    "1. Pattern-Based vs Smart-Fill vs Backfill ì „ëµ ë¹„êµ\n",
    "2. ê° ì „ëµì˜ ê²°ì¸¡ì¹˜ ì˜ˆì¸¡ í’ˆì§ˆ í‰ê°€\n",
    "3. ì‹¤ì œê°’ê³¼ ì±„ìš´ê°’ì˜ gap ì¸¡ì •\n",
    "4. ìµœì¢… ì¶”ì²œ ì „ëµ ì„ ì •\n",
    "\n",
    "**ì „ëµ:**\n",
    "- `pattern_based`: ìœ ì‚¬ íŒ¨í„´ featureë¡œ ì„ í˜• íšŒê·€ ì˜ˆì¸¡ (NEW)\n",
    "- `smart_fill`: ê·¸ë£¹ë³„ ì§€ëŠ¥í˜• ì±„ì›€ (M/V/S=median, E/I/P=backfill)\n",
    "- `backfill`: ë‹¨ìˆœ backfill (baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Get project root\n",
    "notebook_dir = os.getcwd() if '__file__' not in dir() else os.path.dirname(os.path.abspath(__file__))\n",
    "project_root = os.path.dirname(notebook_dir) if 'notebooks' in notebook_dir else notebook_dir\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Project utilities\n",
    "from src.data import DataLoader\n",
    "from src.utils import set_seed, load_config\n",
    "\n",
    "# Load configuration\n",
    "os.chdir(project_root)\n",
    "config_path = os.path.join(project_root, 'conf', 'params.yaml')\n",
    "config = load_config(config_path)\n",
    "set_seed(config['seed'])\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.6f}'.format)\n",
    "\n",
    "# Plot settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (16, 6)\n",
    "\n",
    "print('âœ… Setup complete!')\n",
    "print(f'ğŸ“‚ Working directory: {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 2. Load Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DataLoader\n",
    "loader = DataLoader()\n",
    "\n",
    "# Load original data (with missing values)\n",
    "train_df, test_df = loader.load_data()\n",
    "\n",
    "print(f'ğŸ“¦ Train: {train_df.shape}, Test: {test_df.shape}')\n",
    "print(f'ğŸ“… Date range: {train_df[\"date_id\"].min()} - {train_df[\"date_id\"].max()}')\n",
    "\n",
    "# Get missing summary\n",
    "missing_summary = loader.get_missing_summary(train_df)\n",
    "print(f'\\nğŸ“Š Features with missing values: {len(missing_summary)}')\n",
    "print(f'Total missing cells: {missing_summary[\"missing_count\"].sum()}')\n",
    "\n",
    "display(missing_summary.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 3. Strategy Comparison Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define strategies to test\n",
    "strategies = {\n",
    "    'pattern_based': 'ìœ ì‚¬ íŒ¨í„´ í™œìš© (Pattern-Based Imputation)',\n",
    "    'smart_fill': 'ê·¸ë£¹ë³„ ì§€ëŠ¥í˜• ì±„ì›€ (Group-Specific Fill)',\n",
    "    'backfill': 'ë‹¨ìˆœ Backfill (Baseline)'\n",
    "}\n",
    "\n",
    "# Store processed dataframes\n",
    "processed_dfs = {}\n",
    "results = []\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MISSING VALUE STRATEGY COMPARISON EXPERIMENT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for strategy_name, description in strategies.items():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Testing: {description}\")\n",
    "    print(f\"Strategy: {strategy_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Process data with this strategy\n",
    "    train_processed = loader.handle_missing_values(\n",
    "        train_df.copy(), \n",
    "        strategy=strategy_name\n",
    "    )\n",
    "    \n",
    "    # Store processed dataframe\n",
    "    processed_dfs[strategy_name] = train_processed\n",
    "    \n",
    "    # Check remaining missing values\n",
    "    remaining = train_processed.isnull().sum().sum()\n",
    "    print(f\"\\nâœ… Remaining missing values: {remaining}\")\n",
    "    \n",
    "    results.append({\n",
    "        'strategy': strategy_name,\n",
    "        'description': description,\n",
    "        'remaining_missing': remaining\n",
    "    })\n",
    "\n",
    "# Results summary\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STRATEGY COMPARISON SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## 4. Quality Assessment: Gap from First Valid Value\n",
    "\n",
    "ê° ì „ëµì´ ì±„ìš´ ê°’ì´ ì‹¤ì œ ì²« ìœ íš¨ê°’ê³¼ ì–¼ë§ˆë‚˜ ê°€ê¹Œìš´ì§€ ì¸¡ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features with high missing % for detailed analysis\n",
    "test_features = missing_summary.nlargest(10, 'missing_pct')['feature'].tolist()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"IMPUTATION QUALITY ASSESSMENT\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nAnalyzing top 10 features with highest missing %:\\n\")\n",
    "\n",
    "quality_results = []\n",
    "\n",
    "for feature in test_features:\n",
    "    # Get first valid index from original data\n",
    "    first_valid_idx = train_df[feature].first_valid_index()\n",
    "    \n",
    "    if first_valid_idx is None or first_valid_idx == 0:\n",
    "        continue\n",
    "    \n",
    "    # Actual first valid value\n",
    "    actual_value = train_df.loc[first_valid_idx, feature]\n",
    "    \n",
    "    print(f\"\\n{'â”€'*80}\")\n",
    "    print(f\"Feature: {feature}\")\n",
    "    print(f\"First valid index: {first_valid_idx}\")\n",
    "    print(f\"Actual first value: {actual_value:.6f}\")\n",
    "    print(f\"{'â”€'*80}\")\n",
    "    \n",
    "    for strategy_name in strategies.keys():\n",
    "        # Get filled values (before first valid index)\n",
    "        filled_period = processed_dfs[strategy_name].loc[:first_valid_idx-1, feature]\n",
    "        \n",
    "        if len(filled_period) > 0 and not filled_period.isna().all():\n",
    "            # Calculate metrics\n",
    "            mean_filled = filled_period.mean()\n",
    "            std_filled = filled_period.std()\n",
    "            gap = abs(mean_filled - actual_value)\n",
    "            gap_pct = (gap / abs(actual_value) * 100) if actual_value != 0 else np.nan\n",
    "            \n",
    "            print(f\"  {strategy_name:15s}: Mean={mean_filled:10.6f}, Gap={gap:8.6f} ({gap_pct:6.2f}%)\")\n",
    "            \n",
    "            quality_results.append({\n",
    "                'feature': feature,\n",
    "                'strategy': strategy_name,\n",
    "                'actual_value': actual_value,\n",
    "                'mean_filled': mean_filled,\n",
    "                'std_filled': std_filled,\n",
    "                'gap': gap,\n",
    "                'gap_pct': gap_pct\n",
    "            })\n",
    "\n",
    "# Convert to DataFrame\n",
    "quality_df = pd.DataFrame(quality_results)\n",
    "\n",
    "# Aggregate by strategy\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AVERAGE GAP BY STRATEGY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "strategy_quality = quality_df.groupby('strategy').agg({\n",
    "    'gap': ['mean', 'median', 'std'],\n",
    "    'gap_pct': ['mean', 'median']\n",
    "}).round(4)\n",
    "\n",
    "display(strategy_quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## 4.5. Pattern-Based Diagnosis: ì‹¤ì œ ì‘ë™ ì—¬ë¶€ í™•ì¸\n",
    "\n",
    "Pattern-basedê°€ ì‹¤ì œë¡œ ìœ ì‚¬ featureë¥¼ ì°¾ì•„ì„œ ì˜ˆì¸¡í–ˆëŠ”ì§€, ì•„ë‹ˆë©´ fallbackë§Œ ì‚¬ìš©í–ˆëŠ”ì§€ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnose: Pattern-basedê°€ ì‹¤ì œë¡œ ì˜ˆì¸¡í–ˆëŠ”ì§€ í™•ì¸\n",
    "print(\"=\"*80)\n",
    "print(\"PATTERN-BASED DIAGNOSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "diagnosis_results = []\n",
    "\n",
    "for feature in test_features:\n",
    "    first_valid_idx = train_df[feature].first_valid_index()\n",
    "    \n",
    "    if first_valid_idx is None or first_valid_idx == 0:\n",
    "        continue\n",
    "    \n",
    "    # Compare pattern_based vs backfill\n",
    "    pattern_filled = processed_dfs['pattern_based'].loc[:first_valid_idx-1, feature]\n",
    "    backfill_filled = processed_dfs['backfill'].loc[:first_valid_idx-1, feature]\n",
    "    \n",
    "    # Check if they are different (meaning pattern-based actually predicted)\n",
    "    is_different = not pattern_filled.equals(backfill_filled)\n",
    "    \n",
    "    if is_different:\n",
    "        # Pattern-based actually used prediction!\n",
    "        mean_diff = abs(pattern_filled.mean() - backfill_filled.mean())\n",
    "        max_diff = abs(pattern_filled - backfill_filled).max()\n",
    "        \n",
    "        diagnosis_results.append({\n",
    "            'feature': feature,\n",
    "            'first_valid_idx': first_valid_idx,\n",
    "            'used_prediction': True,\n",
    "            'mean_diff': mean_diff,\n",
    "            'max_diff': max_diff,\n",
    "            'pattern_mean': pattern_filled.mean(),\n",
    "            'backfill_mean': backfill_filled.mean()\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nâœ… {feature}: USED PATTERN-BASED PREDICTION\")\n",
    "        print(f\"   Missing period: 0 ~ {first_valid_idx-1} ({first_valid_idx} rows)\")\n",
    "        print(f\"   Pattern mean: {pattern_filled.mean():.6f}\")\n",
    "        print(f\"   Backfill mean: {backfill_filled.mean():.6f}\")\n",
    "        print(f\"   Mean diff: {mean_diff:.6f}\")\n",
    "        print(f\"   Max diff: {max_diff:.6f}\")\n",
    "    else:\n",
    "        # Pattern-based used fallback (identical to backfill)\n",
    "        diagnosis_results.append({\n",
    "            'feature': feature,\n",
    "            'first_valid_idx': first_valid_idx,\n",
    "            'used_prediction': False,\n",
    "            'mean_diff': 0.0,\n",
    "            'max_diff': 0.0,\n",
    "            'pattern_mean': pattern_filled.mean(),\n",
    "            'backfill_mean': backfill_filled.mean()\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nâš ï¸  {feature}: USED FALLBACK (identical to backfill)\")\n",
    "        print(f\"   â†’ No similar features found (correlation < 0.7)\")\n",
    "\n",
    "# Summary\n",
    "diagnosis_df = pd.DataFrame(diagnosis_results)\n",
    "predicted_count = diagnosis_df['used_prediction'].sum()\n",
    "fallback_count = len(diagnosis_df) - predicted_count\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"SUMMARY\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Features analyzed: {len(diagnosis_df)}\")\n",
    "print(f\"Used prediction: {predicted_count} ({predicted_count/len(diagnosis_df)*100:.1f}%)\")\n",
    "print(f\"Used fallback: {fallback_count} ({fallback_count/len(diagnosis_df)*100:.1f}%)\")\n",
    "print(f\"\\nâ†’ Pattern-based only works when similar features exist in same group!\")\n",
    "\n",
    "display(diagnosis_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 4.6. ì‹¤í—˜ ê²°ê³¼ í•´ì„\n",
    "\n",
    "### ğŸ“Š í•µì‹¬ ì¸ì‚¬ì´íŠ¸\n",
    "\n",
    "**1. Pattern-BasedëŠ” ëŒ€ë¶€ë¶„ Fallback ì‚¬ìš©**\n",
    "- 10ê°œ feature ì¤‘ **7ê°œëŠ” backfillê³¼ ë™ì¼** (Gap=0.00)\n",
    "- ì´ìœ : ê°™ì€ ê·¸ë£¹ ë‚´ì— ìœ ì‚¬í•œ featureë¥¼ ëª» ì°¾ìŒ (correlation < 0.7)\n",
    "- ë˜ëŠ” ìœ ì‚¬ featureë„ ê°™ì€ ì‹œê¸°ì— missing\n",
    "\n",
    "**2. ì‹¤ì œë¡œ Pattern-Basedê°€ ì‘ë™í•œ ê²½ìš°**\n",
    "- V10, V9, S3 ë“± **3ê°œë§Œ ì‹¤ì œ ì˜ˆì¸¡ ì‚¬ìš©**\n",
    "- í•˜ì§€ë§Œ ì´ ê²½ìš°ì—ë„ backfillë³´ë‹¤ Gapì´ **ë” í¼**\n",
    "- V10: pattern(Gap=1.84) > backfill(Gap=0.00)\n",
    "\n",
    "**3. Smart-Fillì˜ ì¹˜ëª…ì  ë¬¸ì œ**\n",
    "- Median ê°’ì´ ì‹¤ì œ ì²« ìœ íš¨ê°’ê³¼ ë„ˆë¬´ ë‹¤ë¦„\n",
    "- M13: 7575% ì˜¤ì°¨! (median=-1.09 vs actual=0.01)\n",
    "- íŠ¹íˆ M, S ê·¸ë£¹ì—ì„œ ì‹¬ê°í•œ ì˜¤ì°¨ ë°œìƒ\n",
    "\n",
    "### ğŸ’¡ ê²°ë¡ \n",
    "\n",
    "**Backfillì´ ìµœì„ !**\n",
    "- Gap = 0.00 (ì™„ë²½)\n",
    "- ì´ìœ : ì´ˆê¸° ê²°ì¸¡ì¹˜ëŠ” ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ ì „ â†’ ì²« ìœ íš¨ê°’ì´ ê°€ì¥ ì •í™•í•œ ì¶”ì •\n",
    "- Pattern-basedëŠ” ì¢‹ì€ ì•„ì´ë””ì–´ì§€ë§Œ, ì‹¤ì œë¡œëŠ” ìœ ì‚¬ featureë¥¼ ì°¾ê¸° ì–´ë ¤ì›€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## 4.7. Backfill vs Other Methods: ì‹œê°ì  ë¹„êµ\n",
    "\n",
    "ê° ë°©ë²•ì´ ê²°ì¸¡ì¹˜ë¥¼ ì–´ë–»ê²Œ ì±„ìš°ëŠ”ì§€ ì‹œê°ì ìœ¼ë¡œ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backfillì˜ ì •í™•ì„± ê²€ì¦: \"ì²« ìœ íš¨ê°’ ê·¼ì²˜ëŠ” ì–´ë–»ê²Œ ë³€í•˜ëŠ”ê°€?\"\n",
    "print(\"=\"*80)\n",
    "print(\"BACKFILL ì •í™•ì„± ê²€ì¦\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nì§ˆë¬¸: ì²« ìœ íš¨ê°’ìœ¼ë¡œ ê³¼ê±°ë¥¼ ì±„ìš°ëŠ”ê²Œ ì •í™•í•œê°€?\")\n",
    "print(\"ë‹µë³€: ì²« ìœ íš¨ê°’ ì´í›„ ë°ì´í„°ë¥¼ ë³´ë©´ ì•Œ ìˆ˜ ìˆìŒ!\")\n",
    "print(\"\\n\" + \"â”€\"*80)\n",
    "\n",
    "# E7 feature ìƒì„¸ ë¶„ì„\n",
    "feature = 'E7'\n",
    "first_valid_idx = train_df[feature].first_valid_index()\n",
    "\n",
    "if first_valid_idx is not None:\n",
    "    # ì²« ìœ íš¨ê°’ ì´í›„ 100ê°œ ë°ì´í„°\n",
    "    window_start = first_valid_idx\n",
    "    window_end = min(first_valid_idx + 100, len(train_df))\n",
    "    \n",
    "    early_values = train_df.loc[window_start:window_end, feature].dropna()\n",
    "    \n",
    "    print(f\"\\n{feature} - ìˆ˜ì§‘ ì‹œì‘ ì´í›„ ì´ˆê¸° 100ì¼ ë¶„ì„:\")\n",
    "    print(f\"ì²« ìœ íš¨ê°’ (idx={first_valid_idx}): {train_df.loc[first_valid_idx, feature]:.6f}\")\n",
    "    print(f\"\\nì´ˆê¸° 100ì¼ í†µê³„:\")\n",
    "    print(f\"  Mean:   {early_values.mean():.6f}\")\n",
    "    print(f\"  Median: {early_values.median():.6f}\")\n",
    "    print(f\"  Std:    {early_values.std():.6f}\")\n",
    "    print(f\"  Min:    {early_values.min():.6f}\")\n",
    "    print(f\"  Max:    {early_values.max():.6f}\")\n",
    "    \n",
    "    # ì²« ê°’ê³¼ í‰ê· ì˜ ì°¨ì´\n",
    "    gap = abs(train_df.loc[first_valid_idx, feature] - early_values.mean())\n",
    "    print(f\"\\nì²« ê°’ vs ì´ˆê¸° í‰ê·  ì°¨ì´: {gap:.6f}\")\n",
    "    \n",
    "    # ë³€ë™ì„± í™•ì¸\n",
    "    first_10_std = early_values.head(10).std()\n",
    "    print(f\"ì´ˆê¸° 10ì¼ ë³€ë™ì„±(std): {first_10_std:.6f}\")\n",
    "    \n",
    "    print(f\"\\nğŸ’¡ í•´ì„:\")\n",
    "    if first_10_std < early_values.std() * 0.5:\n",
    "        print(f\"   â†’ ì´ˆê¸°ì— ì•ˆì •ì ! ì²« ê°’ìœ¼ë¡œ ê³¼ê±° ì±„ìš°ëŠ”ê²Œ í•©ë¦¬ì  âœ…\")\n",
    "    else:\n",
    "        print(f\"   â†’ ì´ˆê¸°ì— ë³€ë™ì„± í¼! ì²« ê°’ìœ¼ë¡œ ì±„ìš°ëŠ”ê²Œ ë¶€ì •í™•í•  ìˆ˜ ìˆìŒ âš ï¸\")\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "    \n",
    "    # Plot 1: ì´ˆê¸° 100ì¼ ì‹œê³„ì—´\n",
    "    axes[0].plot(range(len(early_values)), early_values.values, \n",
    "                marker='o', markersize=3, linewidth=1.5, label='Actual values')\n",
    "    axes[0].axhline(y=train_df.loc[first_valid_idx, feature], \n",
    "                   color='red', linestyle='--', linewidth=2, \n",
    "                   label=f'First valid: {train_df.loc[first_valid_idx, feature]:.4f}')\n",
    "    axes[0].axhline(y=early_values.mean(), \n",
    "                   color='green', linestyle='--', linewidth=2, alpha=0.7,\n",
    "                   label=f'Mean: {early_values.mean():.4f}')\n",
    "    axes[0].set_title(f'{feature} - ìˆ˜ì§‘ ì‹œì‘ ì´í›„ ì´ˆê¸° 100ì¼', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_xlabel('Days after first valid', fontsize=10)\n",
    "    axes[0].set_ylabel('Value', fontsize=10)\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: ì´ˆê¸° ê°’ë“¤ì˜ ë¶„í¬\n",
    "    axes[1].hist(early_values.values, bins=30, alpha=0.7, edgecolor='black')\n",
    "    axes[1].axvline(x=train_df.loc[first_valid_idx, feature], \n",
    "                   color='red', linestyle='--', linewidth=2, \n",
    "                   label=f'First valid: {train_df.loc[first_valid_idx, feature]:.4f}')\n",
    "    axes[1].axvline(x=early_values.mean(), \n",
    "                   color='green', linestyle='--', linewidth=2,\n",
    "                   label=f'Mean: {early_values.mean():.4f}')\n",
    "    axes[1].set_title(f'{feature} - ì´ˆê¸° 100ì¼ ê°’ ë¶„í¬', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_xlabel('Value', fontsize=10)\n",
    "    axes[1].set_ylabel('Frequency', fontsize=10)\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ê²°ë¡ :\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "âœ… Backfillì´ ì •í™•í•œ ì´ìœ :\n",
    "\n",
    "1. ì´ˆê¸° ê²°ì¸¡ = \"ë°ì´í„° ìˆ˜ì§‘ ì „\" (ê°’ì´ ì—†ì—ˆë˜ê²Œ ì•„ë‹ˆë¼ ì¸¡ì • ì•ˆí•¨)\n",
    "2. ìˆ˜ì§‘ ì‹œì‘ ì‹œì  = ê·¸ ì§ì „ ìƒíƒœë¥¼ ê°€ì¥ ì˜ ë°˜ì˜\n",
    "3. Economic indicatorsëŠ” ê¸‰ë³€í•˜ì§€ ì•ŠìŒ (momentum ìˆìŒ)\n",
    "4. ì‹¤ì œë¡œ ì²« ê°’ ì´í›„ ë°ì´í„°ë¥¼ ë³´ë©´ ì²« ê°’ì´ í‰ê· ì— ê°€ê¹Œì›€\n",
    "\n",
    "âš ï¸ ë°˜ë©´ Median/Meanì€:\n",
    "- ë¯¸ë˜ ë°ì´í„° í¬í•¨ (leakage!)\n",
    "- ì „ì²´ ê¸°ê°„ í‰ê·  â‰  ì´ˆê¸° ì‹œì  ê°’\n",
    "\"\"\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## 4.8. Alternative: ê²°ì¸¡ì¹˜ë¥¼ ì±„ìš°ì§€ ì•Šê³  í•™ìŠµí•˜ê¸°\n",
    "\n",
    "### ğŸ’¡ í•µì‹¬ ì•„ì´ë””ì–´\n",
    "**ì¼ì •í•œ ê°’ìœ¼ë¡œ ì±„ìš°ë©´ â†’ ì¸ìœ„ì  íŒ¨í„´ ìƒì„± â†’ ëª¨ë¸ ì„±ëŠ¥ ì €í•˜ ê°€ëŠ¥**\n",
    "\n",
    "### í•´ê²°ì±… 3ê°€ì§€:\n",
    "1. **Tree ëª¨ë¸**: LightGBMì€ NaNì„ ìë™ ì²˜ë¦¬ (ì¶”ì²œ!)\n",
    "2. **Missing Indicator**: ê²°ì¸¡ ì—¬ë¶€ë¥¼ ë³„ë„ featureë¡œ\n",
    "3. **ì´ˆê¸° ê¸°ê°„ ì œì™¸**: ëª¨ë“  featureê°€ validí•œ ì‹œì ë¶€í„°ë§Œ í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative 1: ì´ˆê¸° ê²°ì¸¡ ê¸°ê°„ ì™„ì „íˆ ì œì™¸\n",
    "print(\"=\"*80)\n",
    "print(\"ALTERNATIVE APPROACH: ì´ˆê¸° ê²°ì¸¡ ê¸°ê°„ ì œì™¸\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ëª¨ë“  featureì˜ ì²« ìœ íš¨ ì¸ë±ìŠ¤ ì°¾ê¸°\n",
    "all_features = [col for group in loader.feature_groups.values() for col in group if col in train_df.columns]\n",
    "\n",
    "first_valid_indices = []\n",
    "for col in all_features:\n",
    "    idx = train_df[col].first_valid_index()\n",
    "    if idx is not None:\n",
    "        first_valid_indices.append(idx)\n",
    "\n",
    "if first_valid_indices:\n",
    "    max_first_valid = max(first_valid_indices)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š ê²°ì¸¡ì¹˜ ë¶„ì„:\")\n",
    "    print(f\"  - ì „ì²´ ë°ì´í„°: {len(train_df)} rows\")\n",
    "    print(f\"  - ëª¨ë“  featureê°€ validí•œ ì‹œì‘ì : index {max_first_valid}\")\n",
    "    print(f\"  - ì œì™¸í•  ì´ˆê¸° ê¸°ê°„: {max_first_valid} rows ({max_first_valid/len(train_df)*100:.1f}%)\")\n",
    "    print(f\"  - ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°: {len(train_df) - max_first_valid} rows ({(len(train_df)-max_first_valid)/len(train_df)*100:.1f}%)\")\n",
    "    \n",
    "    # Clean ë°ì´í„° (ëª¨ë“  featureê°€ valid)\n",
    "    train_clean = train_df.loc[max_first_valid:].copy()\n",
    "    \n",
    "    print(f\"\\nâœ… Clean ë°ì´í„° ìƒì„±:\")\n",
    "    print(f\"  - Shape: {train_clean.shape}\")\n",
    "    print(f\"  - Missing values: {train_clean[all_features].isnull().sum().sum()}\")\n",
    "    \n",
    "    # Featureë³„ missing count\n",
    "    missing_features = []\n",
    "    for col in all_features:\n",
    "        missing = train_clean[col].isnull().sum()\n",
    "        if missing > 0:\n",
    "            missing_features.append({'feature': col, 'missing': missing})\n",
    "    \n",
    "    if missing_features:\n",
    "        print(f\"\\nâš ï¸  Clean ë°ì´í„°ì—ë„ ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” feature: {len(missing_features)}ê°œ\")\n",
    "        missing_df = pd.DataFrame(missing_features).sort_values('missing', ascending=False)\n",
    "        display(missing_df.head(10))\n",
    "    else:\n",
    "        print(f\"\\nâœ¨ Perfect! Clean ë°ì´í„°ì—ëŠ” ê²°ì¸¡ì¹˜ê°€ ì „í˜€ ì—†ìŒ!\")\n",
    "    \n",
    "    # ë°ì´í„° ì†ì‹¤ ë¶„ì„\n",
    "    print(f\"\\nğŸ“‰ ë°ì´í„° ì†ì‹¤ ë¶„ì„:\")\n",
    "    print(f\"  - ì†ì‹¤ëœ ê¸°ê°„: 0 ~ {max_first_valid-1}\")\n",
    "    print(f\"  - ì†ì‹¤ë¥ : {max_first_valid/len(train_df)*100:.1f}%\")\n",
    "    \n",
    "    if max_first_valid > len(train_df) * 0.7:\n",
    "        print(f\"  - âš ï¸  70% ì´ìƒ ì†ì‹¤! ì´ ë°©ë²•ì€ ë¶€ì ì ˆ\")\n",
    "    elif max_first_valid > len(train_df) * 0.5:\n",
    "        print(f\"  - âš ï¸  50% ì´ìƒ ì†ì‹¤! ì‹ ì¤‘í•˜ê²Œ ì‚¬ìš©\")\n",
    "    else:\n",
    "        print(f\"  - âœ… ì†ì‹¤ í—ˆìš© ë²”ìœ„ (50% ë¯¸ë§Œ)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ALTERNATIVE APPROACH í‰ê°€\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "âœ… ì¥ì :\n",
    "1. ì¸ìœ„ì ì¸ íŒ¨í„´ ì—†ìŒ (natural data)\n",
    "2. ëª¨ë“  featureê°€ ì‹¤ì œ ì¸¡ì •ê°’\n",
    "3. LightGBM ê°™ì€ tree ëª¨ë¸ì— ìµœì \n",
    "\n",
    "âš ï¸  ë‹¨ì :\n",
    "1. ë°ì´í„° ì†ì‹¤ (ì´ˆê¸° ê¸°ê°„ ë²„ë¦¼)\n",
    "2. ì‹œê³„ì—´ ê¸¸ì´ ê°ì†Œ â†’ í•™ìŠµ ë°ì´í„° ë¶€ì¡±\n",
    "3. ì´ˆê¸° ì‹œì¥ ìƒí™© ì •ë³´ ì†ì‹¤\n",
    "\n",
    "ğŸ’¡ ì¶”ì²œ:\n",
    "- ì´ˆê¸° ê²°ì¸¡ì´ 30% ë¯¸ë§Œ: ì´ ë°©ë²• ì‚¬ìš© ê³ ë ¤\n",
    "- ì´ˆê¸° ê²°ì¸¡ì´ 50% ì´ìƒ: Backfill + Tree ëª¨ë¸ ì‚¬ìš©\n",
    "- í˜„ì¬ ë°ì´í„°: \"\"\" + f\"{max_first_valid/len(train_df)*100:.1f}%\" + \"\"\" ì†ì‹¤ â†’ \"\"\" + \n",
    "(\"âœ… ì‚¬ìš© ê°€ëŠ¥\" if max_first_valid < len(train_df) * 0.5 else \"âš ï¸  ë¹„ì¶”ì²œ\") +\n",
    "\"\"\"\n",
    "\"\"\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative 2: LightGBMì˜ native missing value handling\n",
    "print(\"=\"*80)\n",
    "print(\"ALTERNATIVE 2: LightGBM Native Missing Handling\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "ğŸ’¡ LightGBMì€ ê²°ì¸¡ì¹˜ë¥¼ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤!\n",
    "\n",
    "ì‘ë™ ë°©ì‹:\n",
    "1. Split ì‹œ NaNì„ ë³„ë„ ì¹´í…Œê³ ë¦¬ë¡œ ì·¨ê¸‰\n",
    "2. \"feature Xê°€ missingì´ë©´ â†’ ì™¼ìª½ ë¸Œëœì¹˜\" ê°™ì€ ê·œì¹™ í•™ìŠµ\n",
    "3. ê²°ì¸¡ íŒ¨í„´ ìì²´ê°€ signalì´ ë  ìˆ˜ ìˆìŒ!\n",
    "\n",
    "ì˜ˆì‹œ:\n",
    "â”œâ”€ E7 is missing? (ì´ˆê¸° ê¸°ê°„)\n",
    "â”‚  â”œâ”€ YES â†’ Prediction A (ë³´ìˆ˜ì  ì˜ˆì¸¡)\n",
    "â”‚  â””â”€ NO â†’ Check E7 value\n",
    "â”‚      â”œâ”€ E7 < 1.0 â†’ Prediction B\n",
    "â”‚      â””â”€ E7 >= 1.0 â†’ Prediction C\n",
    "\n",
    "ì¥ì :\n",
    "âœ… ë°ì´í„° ì†ì‹¤ ì—†ìŒ (ì „ì²´ ê¸°ê°„ ì‚¬ìš©)\n",
    "âœ… ê²°ì¸¡ íŒ¨í„´ì„ ìì—°ìŠ¤ëŸ½ê²Œ í•™ìŠµ\n",
    "âœ… ì¸ìœ„ì  ì±„ì›€ ì—†ìŒ\n",
    "âœ… Tree ëª¨ë¸ì— ìµœì í™”\n",
    "\n",
    "ë‹¨ì :\n",
    "âš ï¸  Linear ëª¨ë¸ì—ëŠ” ì‚¬ìš© ë¶ˆê°€ (NaN í—ˆìš© ì•ˆí•¨)\n",
    "âš ï¸  Neural Networkì—ë„ ë¶€ì í•©\n",
    "\n",
    "ì‚¬ìš©ë²•:\n",
    "```python\n",
    "import lightgbm as lgb\n",
    "\n",
    "# NaNì„ ê·¸ëŒ€ë¡œ ë‘” ì±„ í•™ìŠµ\n",
    "X_train = train_df[feature_cols]  # NaN í¬í•¨ OK!\n",
    "y_train = train_df['forward_returns']\n",
    "\n",
    "model = lgb.LGBMRegressor(\n",
    "    use_missing=True,  # Default: True\n",
    "    zero_as_missing=False  # 0ì„ missingìœ¼ë¡œ ì·¨ê¸‰í• ì§€\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "ğŸ’¡ ì¶”ì²œ:\n",
    "ì´ ëŒ€íšŒëŠ” Tree ëª¨ë¸ ì‚¬ìš© â†’ LightGBM native handling ì‚¬ìš©í•˜ë©´\n",
    "ê²°ì¸¡ì¹˜ ì±„ìš¸ í•„ìš” ì—†ì´ ë°”ë¡œ í•™ìŠµ ê°€ëŠ¥!\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ê²°ë¡ : ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì „ëµ ë¹„êµ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison = pd.DataFrame([\n",
    "    {\n",
    "        'Method': 'Backfill',\n",
    "        'Data Loss': '0%',\n",
    "        'Artificial Pattern': 'âš ï¸  Yes',\n",
    "        'Tree Models': 'âœ… Good',\n",
    "        'Linear Models': 'âœ… Good',\n",
    "        'Recommendation': 'ê°„ë‹¨í•˜ê³  ì•ˆì „'\n",
    "    },\n",
    "    {\n",
    "        'Method': 'LightGBM Native',\n",
    "        'Data Loss': '0%',\n",
    "        'Artificial Pattern': 'âœ… No',\n",
    "        'Tree Models': 'âœ… Excellent',\n",
    "        'Linear Models': 'âŒ Cannot use',\n",
    "        'Recommendation': 'ğŸ† Best for Trees'\n",
    "    },\n",
    "    {\n",
    "        'Method': 'Drop Initial Period',\n",
    "        'Data Loss': f'{max_first_valid/len(train_df)*100:.1f}%',\n",
    "        'Artificial Pattern': 'âœ… No',\n",
    "        'Tree Models': 'âœ… Good',\n",
    "        'Linear Models': 'âœ… Good',\n",
    "        'Recommendation': 'ë°ì´í„° ì†ì‹¤ í¼'\n",
    "    },\n",
    "    {\n",
    "        'Method': 'Smart Fill (Median)',\n",
    "        'Data Loss': '0%',\n",
    "        'Artificial Pattern': 'âš ï¸âš ï¸  Very bad',\n",
    "        'Tree Models': 'âš ï¸  Poor',\n",
    "        'Linear Models': 'âš ï¸  Poor',\n",
    "        'Recommendation': 'âŒ Not recommended'\n",
    "    }\n",
    "])\n",
    "\n",
    "display(comparison)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ¯ ìµœì¢… ì¶”ì²œ\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "1ìˆœìœ„: LightGBM Native Missing Handling\n",
    "   - ê²°ì¸¡ì¹˜ ê·¸ëŒ€ë¡œ ë‘ê³  í•™ìŠµ\n",
    "   - ê°€ì¥ ìì—°ìŠ¤ëŸ½ê³  íš¨ê³¼ì \n",
    "   - ì½”ë“œ: model.fit(X_with_nan, y)\n",
    "\n",
    "2ìˆœìœ„: Backfill (í˜„ì¬ Gap=0.00ì¸ ë°©ë²•)\n",
    "   - ê°„ë‹¨í•˜ê³  ì•ˆì „\n",
    "   - ëª¨ë“  ëª¨ë¸ì— ì‚¬ìš© ê°€ëŠ¥\n",
    "   - í•˜ì§€ë§Œ ì¸ìœ„ì  íŒ¨í„´ ìƒì„±\n",
    "\n",
    "ë¹„ì¶”ì²œ: Smart Fill, Pattern-Based\n",
    "   - Gap í¼ (ë¶€ì •í™•)\n",
    "   - ì¸ìœ„ì  íŒ¨í„´ ì‹¬í•¨\n",
    "\"\"\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## 5. Visualization: Strategy Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot gap comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Boxplot: Gap distribution by strategy\n",
    "quality_df.boxplot(column='gap', by='strategy', ax=axes[0])\n",
    "axes[0].set_title('Gap from Actual Value (Lower is Better)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Strategy', fontsize=12)\n",
    "axes[0].set_ylabel('Absolute Gap', fontsize=12)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "plt.sca(axes[0])\n",
    "plt.xticks(rotation=15)\n",
    "\n",
    "# Barplot: Average gap % by strategy\n",
    "avg_gap_pct = quality_df.groupby('strategy')['gap_pct'].mean().sort_values()\n",
    "avg_gap_pct.plot(kind='bar', ax=axes[1], color=['green', 'orange', 'red'])\n",
    "axes[1].set_title('Average Gap % from Actual Value', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Strategy', fontsize=12)\n",
    "axes[1].set_ylabel('Average Gap %', fontsize=12)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "plt.sca(axes[1])\n",
    "plt.xticks(rotation=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## 6. Feature-Level Comparison (E7 Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed visualization for E7 (highest missing %)\n",
    "example_feature = 'E7'\n",
    "\n",
    "if example_feature in train_df.columns:\n",
    "    first_valid_idx = train_df[example_feature].first_valid_index()\n",
    "    \n",
    "    if first_valid_idx is not None and first_valid_idx > 100:\n",
    "        print(f\"=\"*80)\n",
    "        print(f\"DETAILED ANALYSIS: {example_feature}\")\n",
    "        print(f\"=\"*80)\n",
    "        print(f\"First valid index: {first_valid_idx}\")\n",
    "        print(f\"Missing period: 0 ~ {first_valid_idx-1} ({first_valid_idx} rows)\")\n",
    "        \n",
    "        # Plot comparison\n",
    "        fig, ax = plt.subplots(figsize=(16, 6))\n",
    "        \n",
    "        # Plot range: show missing period + some overlap\n",
    "        plot_start = 0\n",
    "        plot_end = min(first_valid_idx + 500, len(train_df))\n",
    "        \n",
    "        # Original data (only valid part)\n",
    "        ax.plot(train_df.loc[first_valid_idx:plot_end, 'date_id'], \n",
    "                train_df.loc[first_valid_idx:plot_end, example_feature],\n",
    "                label='Original (Valid)', color='black', linewidth=2, alpha=0.7)\n",
    "        \n",
    "        # Filled data for each strategy\n",
    "        colors = {'pattern_based': 'green', 'smart_fill': 'orange', 'backfill': 'red'}\n",
    "        \n",
    "        for strategy_name in strategies.keys():\n",
    "            ax.plot(processed_dfs[strategy_name].loc[plot_start:plot_end, 'date_id'],\n",
    "                   processed_dfs[strategy_name].loc[plot_start:plot_end, example_feature],\n",
    "                   label=f'{strategy_name} (filled)', \n",
    "                   color=colors[strategy_name], linewidth=1.5, alpha=0.6)\n",
    "        \n",
    "        # Mark first valid index\n",
    "        first_valid_date = train_df.loc[first_valid_idx, 'date_id']\n",
    "        ax.axvline(x=first_valid_date, color='blue', linestyle='--', \n",
    "                  linewidth=2, label=f'First valid: {first_valid_date}')\n",
    "        \n",
    "        ax.set_title(f'{example_feature} - Strategy Comparison', fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel('Date ID', fontsize=12)\n",
    "        ax.set_ylabel('Value', fontsize=12)\n",
    "        ax.legend(loc='best')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Zoom in: Missing period only\n",
    "        fig, ax = plt.subplots(figsize=(16, 6))\n",
    "        \n",
    "        for strategy_name in strategies.keys():\n",
    "            ax.plot(processed_dfs[strategy_name].loc[:first_valid_idx-1, 'date_id'],\n",
    "                   processed_dfs[strategy_name].loc[:first_valid_idx-1, example_feature],\n",
    "                   label=f'{strategy_name}', \n",
    "                   color=colors[strategy_name], linewidth=2, marker='o', markersize=2)\n",
    "        \n",
    "        # Actual first value (horizontal line)\n",
    "        actual_val = train_df.loc[first_valid_idx, example_feature]\n",
    "        ax.axhline(y=actual_val, color='black', linestyle='--', \n",
    "                  linewidth=2, label=f'Actual first value: {actual_val:.4f}')\n",
    "        \n",
    "        ax.set_title(f'{example_feature} - Missing Period (Zoomed)', fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel('Date ID', fontsize=12)\n",
    "        ax.set_ylabel('Filled Value', fontsize=12)\n",
    "        ax.legend(loc='best')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(f\"Feature {example_feature} not found in dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## 7. Conclusion & Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"EXPERIMENT CONCLUSION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Ranking by gap\n",
    "ranking = quality_df.groupby('strategy')['gap'].mean().sort_values()\n",
    "\n",
    "print(\"\\nğŸ† Strategy Ranking (by average gap - lower is better):\\n\")\n",
    "for rank, (strategy, gap) in enumerate(ranking.items(), 1):\n",
    "    emoji = \"ğŸ¥‡\" if rank == 1 else \"ğŸ¥ˆ\" if rank == 2 else \"ğŸ¥‰\"\n",
    "    print(f\"{emoji} Rank {rank}: {strategy:15s} - Average Gap: {gap:.6f}\")\n",
    "\n",
    "best_strategy = ranking.index[0]\n",
    "worst_strategy = ranking.index[-1]\n",
    "improvement = (ranking[worst_strategy] - ranking[best_strategy]) / ranking[worst_strategy] * 100\n",
    "\n",
    "print(f\"\\nâœ¨ Best Strategy: {best_strategy}\")\n",
    "print(f\"ğŸ“ˆ Improvement vs worst: {improvement:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RECOMMENDATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nâœ… Use '{best_strategy}' for model training\")\n",
    "print(f\"\\nReason:\")\n",
    "print(f\"  - Lowest gap from actual values\")\n",
    "print(f\"  - Leverages temporal pattern similarity\")\n",
    "print(f\"  - Preserves signal better than simple fill methods\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## 8. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results directory\n",
    "results_dir = os.path.join(project_root, 'results', 'missing_strategy_experiment')\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Save quality comparison\n",
    "quality_df.to_csv(os.path.join(results_dir, 'quality_comparison.csv'), index=False)\n",
    "print(f\"âœ… Saved: {os.path.join(results_dir, 'quality_comparison.csv')}\")\n",
    "\n",
    "# Save strategy summary\n",
    "strategy_quality.to_csv(os.path.join(results_dir, 'strategy_summary.csv'))\n",
    "print(f\"âœ… Saved: {os.path.join(results_dir, 'strategy_summary.csv')}\")\n",
    "\n",
    "# Save ranking\n",
    "ranking_df = pd.DataFrame({\n",
    "    'strategy': ranking.index,\n",
    "    'average_gap': ranking.values,\n",
    "    'rank': range(1, len(ranking)+1)\n",
    "})\n",
    "ranking_df.to_csv(os.path.join(results_dir, 'strategy_ranking.csv'), index=False)\n",
    "print(f\"âœ… Saved: {os.path.join(results_dir, 'strategy_ranking.csv')}\")\n",
    "\n",
    "print(f\"\\nğŸ“ All results saved to: {results_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
