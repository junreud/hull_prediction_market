{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train csv data\n",
    "df = pd.read_csv(\"../data/raw/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y split\n",
    "X = df.drop(columns='forward_returns')\n",
    "y = df['forward_returns']\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname('src'))))\n",
    "from src.cv import PurgedWalkForwardCV\n",
    "\n",
    "cv_split = PurgedWalkForwardCV(n_splits=5, \n",
    "                         embargo=20, \n",
    "                         purge=True,\n",
    "                         purge_period=5,\n",
    "                         train_ratio=0.8)\n",
    "\n",
    "split_df = []\n",
    "for train_idx, val_idx in cv_split.split(X, y):\n",
    "    print(train_idx, val_idx)\n",
    "    \n",
    "    X_train = X.iloc[train_idx]\n",
    "    y_train = y.iloc[train_idx]\n",
    "\n",
    "    X_valid = X.iloc[val_idx]\n",
    "    y_valid = y.iloc[val_idx]\n",
    "\n",
    "    split_df.append((X_train, y_train, X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from lightgbm import LGBMRegressor\n",
    "from src.metric import CompetitionMetric\n",
    "from src.position import PositionOptimizer, create_position_mapper\n",
    "from src.risk import RiskLabeler\n",
    "from src.utils import load_config\n",
    "import numpy as np\n",
    "\n",
    "project_root = Path.cwd()\n",
    "config_path = project_root / \"conf/params.yaml\"\n",
    "if not config_path.exists():\n",
    "    for parent in project_root.parents:\n",
    "        candidate = parent / \"conf/params.yaml\"\n",
    "        if candidate.exists():\n",
    "            config_path = candidate\n",
    "            break\n",
    "if not config_path.exists():\n",
    "    raise FileNotFoundError(f\"conf/params.yaml not found from {project_root}\")\n",
    "\n",
    "config = load_config(str(config_path))\n",
    "return_cfg = config.get(\"model_return\", {}).get(\"lightgbm\", {})\n",
    "risk_cfg = config.get(\"risk\", {}).get(\"lightgbm\", {}).get(\"fixed_params\", {})\n",
    "return_model_params = {\n",
    "    \"n_estimators\": return_cfg.get(\"n_estimators\", 800),\n",
    "    \"learning_rate\": return_cfg.get(\"learning_rate\", 0.05),\n",
    "    \"num_leaves\": return_cfg.get(\"num_leaves\", 64),\n",
    "    \"feature_fraction\": return_cfg.get(\"feature_fraction\", 0.8),\n",
    "    \"bagging_fraction\": return_cfg.get(\"bagging_fraction\", 0.8),\n",
    "    \"bagging_freq\": return_cfg.get(\"bagging_freq\", 5),\n",
    "    \"min_child_samples\": return_cfg.get(\"min_child_samples\", 20),\n",
    "    \"max_depth\": return_cfg.get(\"max_depth\", -1),\n",
    "    \"objective\": return_cfg.get(\"objective\", \"regression\"),\n",
    "    \"random_state\": return_cfg.get(\"random_state\", 42),\n",
    "    \"verbosity\": return_cfg.get(\"verbosity\", -1),\n",
    "    \"n_jobs\": -1\n",
    "}\n",
    "risk_model_params = {\n",
    "    \"n_estimators\": return_cfg.get(\"n_estimators\", 600),\n",
    "    \"learning_rate\": return_cfg.get(\"learning_rate\", 0.05),\n",
    "    \"num_leaves\": risk_cfg.get(\"num_leaves\", 48),\n",
    "    \"feature_fraction\": 0.7,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 5,\n",
    "    \"min_child_samples\": risk_cfg.get(\"min_data_in_leaf\", 15),\n",
    "    \"reg_alpha\": risk_cfg.get(\"lambda_l1\", 0.1),\n",
    "    \"reg_lambda\": risk_cfg.get(\"lambda_l2\", 0.1),\n",
    "    \"objective\": \"regression\",\n",
    "    \"random_state\": risk_cfg.get(\"random_state\", 42),\n",
    "    \"verbosity\": risk_cfg.get(\"verbosity\", -1),\n",
    "    \"n_jobs\": -1\n",
    "}\n",
    "risk_labeler = RiskLabeler(window=config.get(\"risk\", {}).get(\"label\", {}).get(\"window\", 20))\n",
    "metric_calc = CompetitionMetric()\n",
    "fold_results = []\n",
    "\n",
    "for fold_idx, (X_train, y_train, X_valid, y_valid) in enumerate(split_df, start=1):\n",
    "    print(X_train.shape, y_train.shape)\n",
    "    print(X_valid.shape, y_valid.shape)\n",
    "\n",
    "    # 1. Train Return Model on train fold\n",
    "    return_model = LGBMRegressor(**return_model_params)\n",
    "    return_model.fit(X_train, y_train)\n",
    "    train_r_hat = return_model.predict(X_train)\n",
    "\n",
    "    # 2. Train Risk Model on train fold\n",
    "    risk_train_df = pd.concat([X_train, y_train], axis=1).sort_values(\"date_id\").copy()\n",
    "    risk_train_df[\"risk_label\"] = risk_labeler.create_labels(risk_train_df, \"forward_returns\")\n",
    "    risk_targets = risk_train_df[\"risk_label\"].bfill().ffill()\n",
    "    if risk_targets.isna().any():\n",
    "        fallback = risk_train_df[\"forward_returns\"].rolling(window=20, min_periods=5).std()\n",
    "        risk_targets = risk_targets.fillna(fallback).fillna(risk_train_df[\"forward_returns\"].abs())\n",
    "    risk_model = LGBMRegressor(**risk_model_params)\n",
    "    risk_model.fit(risk_train_df[X_train.columns], risk_targets)\n",
    "    train_sigma_hat = risk_model.predict(X_train)\n",
    "\n",
    "    # 3. Optimize Position Strategy on train fold\n",
    "    mapper = create_position_mapper(strategy=\"sharpe_scaling\")\n",
    "    optimizer = PositionOptimizer(mapper)\n",
    "    optimal_params = optimizer.optimize_sharpe_params(\n",
    "        r_hat=train_r_hat,\n",
    "        sigma_hat=train_sigma_hat,\n",
    "        actual_returns=y_train.values\n",
    "    )\n",
    "\n",
    "    # 4. Make predictions on validation fold\n",
    "    valid_r_hat = return_model.predict(X_valid)\n",
    "    valid_sigma_hat = risk_model.predict(X_valid)\n",
    "\n",
    "    # 5. Convert these predictions to positions\n",
    "    valid_positions = mapper.map_positions(\n",
    "        r_hat=valid_r_hat,\n",
    "        sigma_hat=valid_sigma_hat,\n",
    "        k=optimal_params[\"k\"],\n",
    "        b=optimal_params[\"b\"]\n",
    "    )\n",
    "\n",
    "    # 6. Evaluate strategy Sharpe on validation fold\n",
    "    fold_score = metric_calc.calculate_score(\n",
    "        allocations=valid_positions,\n",
    "        forward_returns=y_valid.values\n",
    "    )\n",
    "    fold_results.append(fold_score)\n",
    "    print(\n",
    "        f\"Fold {fold_idx} â†’ score: {fold_score['score']:.4f}, \"\n",
    "        f\"sharpe: {fold_score['sharpe']:.4f}, k={optimal_params['k']:.3f}, b={optimal_params['b']:.3f}\"\n",
    "    )\n",
    "\n",
    "if fold_results:\n",
    "    mean_score = np.mean([res[\"score\"] for res in fold_results])\n",
    "    mean_sharpe = np.mean([res[\"sharpe\"] for res in fold_results])\n",
    "    print(f\"Average validation score: {mean_score:.4f}, Average sharpe: {mean_sharpe:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hull_prediction_market",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
