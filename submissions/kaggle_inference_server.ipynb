{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83c0f27f",
   "metadata": {},
   "source": [
    "# ğŸ¯ Hull Tactical Market Prediction - API Inference Server\n",
    "\n",
    "**Real-time prediction API for Kaggle competition**\n",
    "\n",
    "## ğŸ“Œ Setup Instructions\n",
    "\n",
    "### Step 1: Upload Files to Kaggle Dataset\n",
    "\n",
    "1. **Go to**: https://www.kaggle.com/datasets\n",
    "2. **Click**: \"New Dataset\"\n",
    "3. **Upload ALL files**:\n",
    "   - All `.py` files from `src/` and `scripts/`\n",
    "   - `params.yaml` from `conf/`\n",
    "   - Trained model files from `artifacts/`\n",
    "4. **Name it**: `mydata`\n",
    "5. **Click**: \"Create\"\n",
    "\n",
    "### Step 2: Configure Dataset Name\n",
    "\n",
    "ì…€ 3ì—ì„œ ë°ì´í„°ì…‹ ì´ë¦„ í™•ì¸:\n",
    "\n",
    "```python\n",
    "DATASET_NAME = \"mydata\"  # ì—¬ê¸° í™•ì¸!\n",
    "```\n",
    "\n",
    "### Step 3: Submit to Competition\n",
    "\n",
    "1. **Competition Setting**: Enable \"Internet\" OFF\n",
    "2. **Accelerator**: None (CPU)\n",
    "3. **Click**: \"Submit to Competition\"\n",
    "4. **Wait**: Real-time inference on hidden test set\n",
    "\n",
    "## ğŸš€ How It Works:\n",
    "\n",
    "1. **Load trained models** (return + risk models)\n",
    "2. **Setup predict() function** for real-time inference\n",
    "3. **Kaggle calls predict()** with each batch of test data\n",
    "4. **Return allocation** in real-time (< 5 min per batch)\n",
    "\n",
    "**Good luck! ğŸš€**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543616bf",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ Setup: Configure Dataset Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0316fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "# ========== CONFIGURATION: ë°ì´í„°ì…‹ ì´ë¦„ (ì—¬ê¸°ë§Œ ìˆ˜ì •í•˜ì„¸ìš”!) ==========\n",
    "DATASET_NAME = \"mydata\"\n",
    "# ====================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SETTING UP PATHS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Kaggle ë°ì´í„°ì…‹ ê²½ë¡œ\n",
    "DATASET_PATH = Path(f\"/kaggle/input/{DATASET_NAME}\")\n",
    "\n",
    "if DATASET_PATH.exists():\n",
    "    sys.path.insert(0, str(DATASET_PATH))\n",
    "    print(f\"âœ“ Dataset found: {DATASET_PATH}\")\n",
    "    \n",
    "    # ========== src ëª¨ë“ˆ ê°€ìƒ ìƒì„± ==========\n",
    "    import importlib.util\n",
    "    import types\n",
    "    \n",
    "    src_module = types.ModuleType('src')\n",
    "    src_module.__path__ = [str(DATASET_PATH)]\n",
    "    sys.modules['src'] = src_module\n",
    "    \n",
    "    # ì˜ì¡´ì„± ìˆœì„œëŒ€ë¡œ ëª¨ë“ˆ ë¡œë“œ\n",
    "    py_files_to_load = [\n",
    "        'utils', 'metric', 'cv', 'data', 'features', 'models', \n",
    "        'tuner', 'backtest', 'position', 'risk', 'interpretability', \n",
    "        'ensemble', 'timeseries_risk'\n",
    "    ]\n",
    "    \n",
    "    for module_name in py_files_to_load:\n",
    "        py_file = DATASET_PATH / f\"{module_name}.py\"\n",
    "        if py_file.exists():\n",
    "            full_module_name = f\"src.{module_name}\"\n",
    "            spec = importlib.util.spec_from_file_location(full_module_name, py_file)\n",
    "            if spec and spec.loader:\n",
    "                module = importlib.util.module_from_spec(spec)\n",
    "                sys.modules[full_module_name] = module\n",
    "                setattr(src_module, module_name, module)\n",
    "                try:\n",
    "                    spec.loader.exec_module(module)\n",
    "                    print(f\"  âœ“ Loaded: src.{module_name}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  âš ï¸  Error loading src.{module_name}: {e}\")\n",
    "    \n",
    "    print(f\"\\nâœ“ Created virtual 'src' module\")\n",
    "    \n",
    "    # Working directory ì„¤ì •\n",
    "    os.chdir(\"/kaggle/working\")\n",
    "    print(f\"âœ“ Working directory: {os.getcwd()}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"âŒ Dataset not found: {DATASET_PATH}\")\n",
    "    input_dir = Path(\"/kaggle/input/\")\n",
    "    if input_dir.exists():\n",
    "        for item in input_dir.iterdir():\n",
    "            print(f\"  ğŸ“ {item.name}\")\n",
    "    raise FileNotFoundError(f\"Dataset '{DATASET_NAME}' not found!\")\n",
    "\n",
    "# ========== CONFIG ë³µì‚¬ ==========\n",
    "config_path = DATASET_PATH / \"params.yaml\"\n",
    "if config_path.exists():\n",
    "    working_config_dir = Path(\"/kaggle/working/conf\")\n",
    "    working_config_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    import shutil\n",
    "    shutil.copy(config_path, working_config_dir / \"params.yaml\")\n",
    "    \n",
    "    # conf ë””ë ‰í† ë¦¬ë¥¼ Python pathì— ì¶”ê°€\n",
    "    sys.path.insert(0, str(working_config_dir.parent))\n",
    "    print(f\"\\nâœ“ Config copied to: {working_config_dir}/params.yaml\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸  Config file not found: {config_path}\")\n",
    "\n",
    "print(\"\\nâœ… Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea654a8c",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Load Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8835c69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"LOADING TRAINED MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "import pickle\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "# ëª¨ë¸ ê²½ë¡œ\n",
    "MODEL_DIR = DATASET_PATH / \"artifacts\"\n",
    "\n",
    "# Return model ë¡œë“œ\n",
    "return_model_path = MODEL_DIR / \"models_optimized\" / \"return_model.pkl\"\n",
    "if return_model_path.exists():\n",
    "    with open(return_model_path, 'rb') as f:\n",
    "        return_model = pickle.load(f)\n",
    "    print(f\"âœ“ Loaded return model from {return_model_path}\")\n",
    "else:\n",
    "    print(f\"âš ï¸  Return model not found: {return_model_path}\")\n",
    "    return_model = None\n",
    "\n",
    "# Risk model ë¡œë“œ\n",
    "risk_model_path = MODEL_DIR / \"models_risk_optimized\" / \"risk_model.pkl\"\n",
    "if risk_model_path.exists():\n",
    "    with open(risk_model_path, 'rb') as f:\n",
    "        risk_model = pickle.load(f)\n",
    "    print(f\"âœ“ Loaded risk model from {risk_model_path}\")\n",
    "else:\n",
    "    print(f\"âš ï¸  Risk model not found: {risk_model_path}\")\n",
    "    risk_model = None\n",
    "\n",
    "# Position strategy íŒŒë¼ë¯¸í„° ë¡œë“œ\n",
    "strategy_path = MODEL_DIR / \"position_strategy.json\"\n",
    "if strategy_path.exists():\n",
    "    import json\n",
    "    with open(strategy_path, 'r') as f:\n",
    "        strategy_params = json.load(f)\n",
    "    print(f\"âœ“ Loaded position strategy from {strategy_path}\")\n",
    "else:\n",
    "    print(f\"âš ï¸  Position strategy not found: {strategy_path}\")\n",
    "    strategy_params = {}\n",
    "\n",
    "print(\"\\nâœ… Model loading complete!\")\n",
    "print(f\"  Return model: {'âœ“' if return_model else 'âœ—'}\")\n",
    "print(f\"  Risk model: {'âœ“' if risk_model else 'âœ—'}\")\n",
    "print(f\"  Strategy params: {'âœ“' if strategy_params else 'âœ—'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6195bc9",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Define Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845832e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from src.features import FeatureEngineering\n",
    "from src.position import SharpeScalingMapper\n",
    "\n",
    "def predict(test: pl.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    Real-time prediction function called by Kaggle API.\n",
    "    \n",
    "    Args:\n",
    "        test: Polars DataFrame with batch of test features\n",
    "        \n",
    "    Returns:\n",
    "        allocation: float between 0.0 and 2.0\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert to pandas for feature engineering\n",
    "        test_pd = test.to_pandas()\n",
    "        \n",
    "        # Feature engineering\n",
    "        fe = FeatureEngineering()\n",
    "        test_features = fe.transform(test_pd)\n",
    "        \n",
    "        # Get selected features\n",
    "        feature_cols = [col for col in test_features.columns \n",
    "                       if col not in ['date_id', 'return_1d', 'symbol']]\n",
    "        \n",
    "        # Predict return (r_hat)\n",
    "        if return_model is not None:\n",
    "            r_hat = return_model.predict(test_features[feature_cols])\n",
    "        else:\n",
    "            r_hat = 0.0\n",
    "        \n",
    "        # Predict risk (sigma_hat)\n",
    "        if risk_model is not None:\n",
    "            sigma_hat = risk_model.predict(test_features[feature_cols])\n",
    "        else:\n",
    "            sigma_hat = 0.1  # default risk\n",
    "        \n",
    "        # Map to position using strategy\n",
    "        mapper = SharpeScalingMapper(**strategy_params)\n",
    "        allocation = mapper.map(r_hat, sigma_hat)\n",
    "        \n",
    "        # Ensure within bounds [0, 2]\n",
    "        allocation = max(0.0, min(2.0, float(allocation)))\n",
    "        \n",
    "        return allocation\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Prediction error: {e}\")\n",
    "        return 0.0  # Safe default\n",
    "\n",
    "print(\"âœ… Prediction function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d15f65",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Start Inference Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34504678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import kaggle_evaluation.default_inference_server\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"STARTING INFERENCE SERVER\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create inference server\n",
    "inference_server = kaggle_evaluation.default_inference_server.DefaultInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    # Production: Serve API for hidden test set\n",
    "    print(\"ğŸš€ Running in COMPETITION mode - serving real-time predictions\")\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    # Local testing: Run on public test set\n",
    "    print(\"ğŸ§ª Running in LOCAL mode - testing on public data\")\n",
    "    inference_server.run_local_gateway(('/kaggle/input/hull-tactical-market-prediction/',))\n",
    "\n",
    "print(\"\\nâœ… Inference server started!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47db566",
   "metadata": {},
   "source": [
    "## ğŸ“Š Submission Checklist\n",
    "\n",
    "### ğŸ¯ Before Submitting:\n",
    "\n",
    "1. âœ… Train models locally and save to `artifacts/`\n",
    "   - `artifacts/models_optimized/return_model.pkl`\n",
    "   - `artifacts/models_risk_optimized/risk_model.pkl`\n",
    "   - `artifacts/position_strategy.json`\n",
    "\n",
    "2. âœ… Upload to Kaggle Dataset (`mydata`)\n",
    "   - All `.py` files from `src/` and `scripts/`\n",
    "   - `params.yaml` from `conf/`\n",
    "   - `artifacts/` folder with trained models\n",
    "\n",
    "3. âœ… Set `DATASET_NAME = \"mydata\"` in Cell 3\n",
    "\n",
    "4. âœ… Competition Settings:\n",
    "   - Internet: **OFF**\n",
    "   - Accelerator: **None** (CPU)\n",
    "\n",
    "5. âœ… Click \"Submit to Competition\"\n",
    "\n",
    "### âš¡ How API Works:\n",
    "\n",
    "```\n",
    "Kaggle loads notebook â†’ Load models â†’ Start server â†’ \n",
    "For each batch: Call predict() â†’ Return allocation â†’ Next batch\n",
    "```\n",
    "\n",
    "**Response time: < 5 minutes per batch**\n",
    "\n",
    "**Good luck! ğŸš€**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
