{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# ğŸ¯ Hull Tactical Market Prediction - Simple Pipeline\n",
    "\n",
    "**3ê°œì˜ ìŠ¤í¬ë¦½íŠ¸ë§Œ ì‹¤í–‰í•˜ë©´ ë!**\n",
    "\n",
    "## ğŸ“Œ Setup Instructions\n",
    "\n",
    "### Step 1: Upload Files to Kaggle Dataset\n",
    "\n",
    "1. **Go to**: https://www.kaggle.com/datasets\n",
    "2. **Click**: \"New Dataset\"\n",
    "3. **Upload ALL files**:\n",
    "   - All `.py` files from `src/` and `scripts/`\n",
    "   - `params.yaml` from `conf/`\n",
    "4. **Name it**: `mydata`\n",
    "5. **Click**: \"Create\"\n",
    "\n",
    "### Step 2: Configure Dataset Name\n",
    "\n",
    "ì…€ 3ì—ì„œ ë°ì´í„°ì…‹ ì´ë¦„ í™•ì¸:\n",
    "\n",
    "```python\n",
    "DATASET_NAME = \"mydata\"  # ì—¬ê¸° í™•ì¸!\n",
    "```\n",
    "\n",
    "### Step 3: Run Notebook\n",
    "\n",
    "1. **Accelerator**: None (CPUë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤)\n",
    "2. **Click**: \"Run All\"\n",
    "3. **Wait**: ~2-3 minutes\n",
    "4. **Download**: `submissions/submission.parquet`\n",
    "5. **Submit**: Upload to competition\n",
    "\n",
    "## ğŸš€ Pipeline:\n",
    "\n",
    "1. **optimize_return_model.py** (~1 min)\n",
    "   - Feature engineering + selection\n",
    "   - Train LightGBM return model (5-fold CV)\n",
    "\n",
    "2. **optimize_risk_model.py** (~1 min)\n",
    "   - Create risk labels\n",
    "   - Train LightGBM risk model (5-fold CV)\n",
    "\n",
    "3. **optimize_position_strategy.py** (~30 sec)\n",
    "   - Optimize position mapping\n",
    "   - Generate submission.parquet\n",
    "\n",
    "**Total: ~2-3 minutes** âš¡\n",
    "\n",
    "Good luck! ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ Setup: Configure Dataset Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "# ========== CONFIGURATION: ë°ì´í„°ì…‹ ì´ë¦„ (ì—¬ê¸°ë§Œ ìˆ˜ì •í•˜ì„¸ìš”!) ==========\n",
    "DATASET_NAME = \"mydata\"\n",
    "# ====================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SETTING UP PATHS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Kaggle ë°ì´í„°ì…‹ ê²½ë¡œ\n",
    "DATASET_PATH = Path(f\"/kaggle/input/{DATASET_NAME}\")\n",
    "\n",
    "if DATASET_PATH.exists():\n",
    "    sys.path.insert(0, str(DATASET_PATH))\n",
    "    print(f\"âœ“ Dataset found: {DATASET_PATH}\")\n",
    "    \n",
    "    # ========== src ëª¨ë“ˆ ê°€ìƒ ìƒì„± ==========\n",
    "    import importlib.util\n",
    "    import types\n",
    "    \n",
    "    src_module = types.ModuleType('src')\n",
    "    src_module.__path__ = [str(DATASET_PATH)]\n",
    "    sys.modules['src'] = src_module\n",
    "    \n",
    "    # ì˜ì¡´ì„± ìˆœì„œëŒ€ë¡œ ëª¨ë“ˆ ë¡œë“œ\n",
    "    py_files_to_load = [\n",
    "        'utils', 'metric', 'cv', 'data', 'features', 'models', \n",
    "        'tuner', 'backtest', 'position', 'risk', 'interpretability', \n",
    "        'ensemble', 'timeseries_risk'\n",
    "    ]\n",
    "    \n",
    "    for module_name in py_files_to_load:\n",
    "        py_file = DATASET_PATH / f\"{module_name}.py\"\n",
    "        if py_file.exists():\n",
    "            full_module_name = f\"src.{module_name}\"\n",
    "            spec = importlib.util.spec_from_file_location(full_module_name, py_file)\n",
    "            if spec and spec.loader:\n",
    "                module = importlib.util.module_from_spec(spec)\n",
    "                sys.modules[full_module_name] = module\n",
    "                setattr(src_module, module_name, module)\n",
    "                try:\n",
    "                    spec.loader.exec_module(module)\n",
    "                    print(f\"  âœ“ Loaded: src.{module_name}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  âš ï¸  Error loading src.{module_name}: {e}\")\n",
    "    \n",
    "    print(f\"\\nâœ“ Created virtual 'src' module\")\n",
    "    \n",
    "    # Working directory ì„¤ì •\n",
    "    os.chdir(\"/kaggle/working\")\n",
    "    print(f\"âœ“ Working directory: {os.getcwd()}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"âŒ Dataset not found: {DATASET_PATH}\")\n",
    "    input_dir = Path(\"/kaggle/input/\")\n",
    "    if input_dir.exists():\n",
    "        for item in input_dir.iterdir():\n",
    "            print(f\"  ğŸ“ {item.name}\")\n",
    "    raise FileNotFoundError(f\"Dataset '{DATASET_NAME}' not found!\")\n",
    "\n",
    "# ========== CONFIG ë³µì‚¬ ==========\n",
    "config_path = DATASET_PATH / \"params.yaml\"\n",
    "if config_path.exists():\n",
    "    working_config_dir = Path(\"/kaggle/working/conf\")\n",
    "    working_config_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    import shutil\n",
    "    shutil.copy(config_path, working_config_dir / \"params.yaml\")\n",
    "    \n",
    "    # conf ë””ë ‰í† ë¦¬ë¥¼ Python pathì— ì¶”ê°€\n",
    "    sys.path.insert(0, str(working_config_dir.parent))\n",
    "    print(f\"\\nâœ“ Config copied to: {working_config_dir}/params.yaml\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸  Config file not found: {config_path}\")\n",
    "\n",
    "print(\"\\nâœ… Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Script 1: Train Return Model (~10 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"STEP 1/3: TRAINING RETURN MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "import shutil\n",
    "\n",
    "# Copy data files\n",
    "data_dir = Path(\"/kaggle/working/data/raw\")\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_src = Path(\"/kaggle/input/hull-tactical-market-prediction/train.csv\")\n",
    "test_src = Path(\"/kaggle/input/hull-tactical-market-prediction/test.csv\")\n",
    "\n",
    "if train_src.exists():\n",
    "    shutil.copy(train_src, data_dir / \"train.csv\")\n",
    "    print(f\"âœ“ Copied train.csv\")\n",
    "\n",
    "if test_src.exists():\n",
    "    shutil.copy(test_src, data_dir / \"test.csv\")\n",
    "    print(f\"âœ“ Copied test.csv\")\n",
    "\n",
    "# Run optimize_return_model.py\n",
    "script_path = DATASET_PATH / \"optimize_return_model.py\"\n",
    "\n",
    "if script_path.exists():\n",
    "    print(f\"\\nâ–¶ Running: {script_path.name}\\n\")\n",
    "    %run {script_path}\n",
    "    print(\"\\nâœ… Return model training complete!\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Script not found: {script_path}\")\n",
    "\n",
    "print(\"\\nğŸ“Š Results saved to: artifacts/models_optimized/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Script 2: Train Risk Model (~10 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"STEP 2/3: TRAINING RISK MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "script_path = DATASET_PATH / \"optimize_risk_model.py\"\n",
    "\n",
    "if script_path.exists():\n",
    "    print(f\"â–¶ Running: {script_path.name}\\n\")\n",
    "    %run {script_path}\n",
    "    print(\"\\nâœ… Risk model training complete!\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Script not found: {script_path}\")\n",
    "\n",
    "print(\"\\nğŸ“Š Results saved to: artifacts/models_risk_optimized/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Script 3: Optimize Position Strategy + Generate Submission (~10 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"STEP 3/3: GENERATING SUBMISSION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "script_path = DATASET_PATH / \"optimize_position_strategy.py\"\n",
    "\n",
    "if script_path.exists():\n",
    "    print(f\"â–¶ Running: {script_path.name}\\n\")\n",
    "    %run {script_path}\n",
    "    print(\"\\nâœ… Submission generation complete!\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Script not found: {script_path}\")\n",
    "\n",
    "# Verify submission\n",
    "submission_path = Path(\"submissions/submission.parquet\")\n",
    "if submission_path.exists():\n",
    "    import pandas as pd\n",
    "    submission = pd.read_parquet(submission_path)\n",
    "    print(f\"\\nâœ… Submission verified:\")\n",
    "    print(f\"  - Rows: {len(submission):,}\")\n",
    "    print(f\"  - Allocation range: [{submission['allocation'].min():.4f}, {submission['allocation'].max():.4f}]\")\n",
    "    print(f\"  - Mean allocation: {submission['allocation'].mean():.4f}\")\n",
    "    print(f\"\\nğŸ“¥ Download 'submissions/submission.parquet' and submit!\")\n",
    "else:\n",
    "    print(f\"\\nâŒ Submission file not found: {submission_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## ğŸ“Š Pipeline Summary\n",
    "\n",
    "### Workflow:\n",
    "```\n",
    "Setup (Cell 3) â†’ Return Model (Cell 4) â†’ Risk Model (Cell 5) â†’ Submission (Cell 6)\n",
    "```\n",
    "\n",
    "**Total Time: ~2-3 minutes** (ë°ì´í„°ê°€ ì‘ì•„ì„œ CPUë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤)\n",
    "\n",
    "### ğŸ¯ Ready!\n",
    "\n",
    "1. âœ… Upload files to Kaggle Dataset (`mydata`)\n",
    "2. âœ… Set Accelerator to **None** (CPU)\n",
    "3. âœ… Click \"Run All\"\n",
    "4. âœ… Download `submissions/submission.parquet`\n",
    "5. âœ… Submit!\n",
    "\n",
    "**Good luck! ğŸš€**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
