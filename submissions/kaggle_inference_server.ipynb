{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# ğŸ¯ Hull Tactical Market Prediction - Training & Inference\n",
    "\n",
    "**Kaggleì—ì„œ ëª¨ë¸ í•™ìŠµ í›„ ì‹¤ì‹œê°„ ì˜ˆì¸¡ API ì œê³µ**\n",
    "\n",
    "## ğŸ“Œ Setup Instructions\n",
    "\n",
    "### Step 1: Upload Files to Kaggle Dataset\n",
    "\n",
    "1. **Go to**: https://www.kaggle.com/datasets\n",
    "2. **Click**: \"New Dataset\"\n",
    "3. **Upload files**:\n",
    "   - All `.py` files from `src/`\n",
    "   - All `.py` files from `scripts/`\n",
    "   - `params.yaml` from `conf/`\n",
    "4. **Name it**: `mydata`\n",
    "5. **Click**: \"Create\"\n",
    "\n",
    "### Step 2: Configure Dataset Name\n",
    "\n",
    "ì…€ 2ì—ì„œ ë°ì´í„°ì…‹ ì´ë¦„ í™•ì¸:\n",
    "\n",
    "```python\n",
    "DATASET_NAME = \"mydata\"  # ì—¬ê¸° í™•ì¸!\n",
    "```\n",
    "\n",
    "### Step 3: Submit to Competition\n",
    "\n",
    "1. **Competition Setting**: Enable \"Internet\" OFF\n",
    "2. **Accelerator**: None (CPU)\n",
    "3. **Click**: \"Submit to Competition\"\n",
    "4. **Wait**: í•™ìŠµ ì™„ë£Œ í›„ ì‹¤ì‹œê°„ inference ì‹œì‘\n",
    "\n",
    "## ğŸš€ How It Works:\n",
    "\n",
    "1. **Train return model** (~10 min)\n",
    "2. **Train risk model** (~10 min)\n",
    "3. **Optimize position strategy** (~5 min)\n",
    "4. **Load trained models**\n",
    "5. **Start inference server** for real-time predictions\n",
    "\n",
    "**Total time: ~25 minutes + inference**\n",
    "\n",
    "**Good luck! ğŸš€**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ Setup: Configure Dataset Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "# ========== CONFIGURATION: ë°ì´í„°ì…‹ ì´ë¦„ (ì—¬ê¸°ë§Œ ìˆ˜ì •í•˜ì„¸ìš”!) ==========\n",
    "DATASET_NAME = \"my-hull-models\"  # â† ì—…ë¡œë“œí•œ dataset ì´ë¦„\n",
    "# ====================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SETTING UP PATHS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Kaggle ë°ì´í„°ì…‹ ê²½ë¡œ\n",
    "DATASET_PATH = Path(f\"/kaggle/input/{DATASET_NAME}\")\n",
    "\n",
    "if DATASET_PATH.exists():\n",
    "    # Add dataset path to sys.path for imports\n",
    "    sys.path.insert(0, str(DATASET_PATH))\n",
    "    print(f\"âœ“ Dataset found: {DATASET_PATH}\")\n",
    "    print(f\"âœ“ Added to sys.path: {DATASET_PATH}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"âŒ Dataset not found: {DATASET_PATH}\")\n",
    "    input_dir = Path(\"/kaggle/input/\")\n",
    "    if input_dir.exists():\n",
    "        print(\"\\nğŸ“ Available datasets:\")\n",
    "        for item in input_dir.iterdir():\n",
    "            print(f\"  - {item.name}\")\n",
    "    raise FileNotFoundError(f\"Dataset '{DATASET_NAME}' not found!\")\n",
    "\n",
    "# ========== CONFIG ë³µì‚¬ ==========\n",
    "config_path = DATASET_PATH / \"conf\" / \"params.yaml\"\n",
    "if config_path.exists():\n",
    "    working_config_dir = Path(\"/kaggle/working/conf\")\n",
    "    working_config_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    import shutil\n",
    "    shutil.copy(config_path, working_config_dir / \"params.yaml\")\n",
    "    \n",
    "    # conf ë””ë ‰í† ë¦¬ë¥¼ Python pathì— ì¶”ê°€\n",
    "    sys.path.insert(0, str(working_config_dir.parent))\n",
    "    print(f\"\\nâœ“ Config copied to: {working_config_dir}/params.yaml\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸  Config file not found: {config_path}\")\n",
    "\n",
    "print(\"\\nâœ… Setup complete!\")\n",
    "print(f\"Python path includes:\")\n",
    "for p in sys.path[:3]:\n",
    "    print(f\"  - {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Train Return Model (~10 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"STEP 1/4: TRAINING RETURN MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Return model í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰\n",
    "script_path = DATASET_PATH / \"scripts\" / \"optimize_return_model.py\"\n",
    "\n",
    "if script_path.exists():\n",
    "    print(f\"â–¶ Running: {script_path.name}\\n\")\n",
    "    %run {script_path}\n",
    "    print(\"\\nâœ… Return model training complete!\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Script not found: {script_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Train Risk Model (~10 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"STEP 2/4: TRAINING RISK MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Risk model í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰\n",
    "script_path = DATASET_PATH / \"scripts\" / \"optimize_risk_model.py\"\n",
    "\n",
    "if script_path.exists():\n",
    "    print(f\"â–¶ Running: {script_path.name}\\n\")\n",
    "    %run {script_path}\n",
    "    print(\"\\nâœ… Risk model training complete!\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Script not found: {script_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Optimize Position Strategy (~5 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"STEP 3/4: OPTIMIZING POSITION STRATEGY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Position strategy ìµœì í™” ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰\n",
    "script_path = DATASET_PATH / \"scripts\" / \"optimize_position_strategy.py\"\n",
    "\n",
    "if script_path.exists():\n",
    "    print(f\"â–¶ Running: {script_path.name}\\n\")\n",
    "    %run {script_path}\n",
    "    print(\"\\nâœ… Position strategy optimization complete!\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Script not found: {script_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ Load Trained Models & Start Inference Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"STEP 4/4: LOADING TRAINED MODELS & STARTING INFERENCE SERVER\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ (Kaggle working directoryì— ìƒì„±ë¨)\n",
    "MODEL_DIR = Path(\"/kaggle/working/artifacts\")\n",
    "\n",
    "# ========== Return models ë¡œë“œ ==========\n",
    "return_models = []\n",
    "return_feature_names = []\n",
    "\n",
    "return_model_dir = MODEL_DIR / \"models_optimized\"\n",
    "if return_model_dir.exists():\n",
    "    # Models ë¡œë“œ\n",
    "    for fold_idx in range(4):\n",
    "        fold_path = return_model_dir / f\"lightgbm_fold_{fold_idx}.pkl\"\n",
    "        if fold_path.exists():\n",
    "            with open(fold_path, 'rb') as f:\n",
    "                model = pickle.load(f)\n",
    "                return_models.append(model)\n",
    "            print(f\"âœ“ Loaded return model fold {fold_idx}\")\n",
    "    \n",
    "    # ëª¨ë¸ì—ì„œ ì§ì ‘ feature names ê°€ì ¸ì˜¤ê¸° (ê°€ì¥ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë°©ë²•)\n",
    "    if return_models:\n",
    "        return_feature_names = return_models[0].feature_name()\n",
    "        print(f\"âœ“ Extracted return feature names from model: {len(return_feature_names)} features\")\n",
    "    else:\n",
    "        raise ValueError(\"No return models loaded!\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Return models not found: {return_model_dir}\")\n",
    "\n",
    "# ========== Risk models ë¡œë“œ ==========\n",
    "risk_models = []\n",
    "risk_feature_names = []\n",
    "\n",
    "risk_model_dir = MODEL_DIR / \"models_risk_optimized\"\n",
    "if risk_model_dir.exists():\n",
    "    # Models ë¡œë“œ\n",
    "    for fold_idx in range(4):\n",
    "        fold_path = risk_model_dir / f\"lightgbm_fold_{fold_idx}.pkl\"\n",
    "        if fold_path.exists():\n",
    "            with open(fold_path, 'rb') as f:\n",
    "                model = pickle.load(f)\n",
    "                risk_models.append(model)\n",
    "            print(f\"âœ“ Loaded risk model fold {fold_idx}\")\n",
    "    \n",
    "    # ëª¨ë¸ì—ì„œ ì§ì ‘ feature names ê°€ì ¸ì˜¤ê¸° (ê°€ì¥ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë°©ë²•)\n",
    "    if risk_models:\n",
    "        risk_feature_names = risk_models[0].feature_name()\n",
    "        print(f\"âœ“ Extracted risk feature names from model: {len(risk_feature_names)} features\")\n",
    "    else:\n",
    "        raise ValueError(\"No risk models loaded!\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Risk models not found: {risk_model_dir}\")\n",
    "\n",
    "# ========== Position strategy ë¡œë“œ ==========\n",
    "strategy_path = MODEL_DIR / \"best_position_strategy.json\"\n",
    "mapper_k = 1.0  # Default\n",
    "mapper_b = 2.0  # Default\n",
    "\n",
    "if strategy_path.exists():\n",
    "    with open(strategy_path, 'r') as f:\n",
    "        strategy_params = json.load(f)\n",
    "    \n",
    "    # SharpeScalingMapperì— í•„ìš”í•œ íŒŒë¼ë¯¸í„°ë§Œ ì¶”ì¶œ\n",
    "    mapper_k = strategy_params.get('k', 1.0)\n",
    "    mapper_b = strategy_params.get('b', 2.0)\n",
    "    \n",
    "    print(f\"âœ“ Loaded position strategy: k={mapper_k}, b={mapper_b}\")\n",
    "else:\n",
    "    print(f\"âš ï¸  Position strategy not found, using defaults: k={mapper_k}, b={mapper_b}\")\n",
    "\n",
    "# ========== Import modules for inference ==========\n",
    "from src.features import FeatureEngineering\n",
    "from src.position import SharpeScalingMapper\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DEFINING PREDICTION FUNCTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def predict(test: pl.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    Real-time prediction function called by Kaggle API.\n",
    "    \n",
    "    Args:\n",
    "        test: Polars DataFrame with batch of test features\n",
    "        \n",
    "    Returns:\n",
    "        allocation: float between 0.0 and 2.0\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert to pandas for feature engineering\n",
    "        test_pd = test.to_pandas()\n",
    "        \n",
    "        # Feature engineering\n",
    "        fe = FeatureEngineering()\n",
    "        test_features = fe.transform(test_pd)\n",
    "\n",
    "        # Use ONLY the features that were used during training\n",
    "        if return_feature_names:\n",
    "            missing_return = [c for c in return_feature_names if c not in test_features.columns]\n",
    "            if missing_return:\n",
    "                print(f\"âš ï¸ Missing {len(missing_return)} return features (filled with 0)\")\n",
    "            \n",
    "            # ì •í™•íˆ í•™ìŠµ ì‹œ ìˆœì„œëŒ€ë¡œ í”¼ì²˜ ìƒì„±\n",
    "            X_return = pd.DataFrame(index=test_features.index)\n",
    "            for feat in return_feature_names:\n",
    "                if feat in test_features.columns:\n",
    "                    X_return[feat] = test_features[feat]\n",
    "                else:\n",
    "                    X_return[feat] = 0.0\n",
    "        else:\n",
    "            raise ValueError(\"Return feature names not loaded!\")\n",
    "        \n",
    "        if risk_feature_names:\n",
    "            missing_risk = [c for c in risk_feature_names if c not in test_features.columns]\n",
    "            if missing_risk:\n",
    "                print(f\"âš ï¸ Missing {len(missing_risk)} risk features (filled with 0)\")\n",
    "            \n",
    "            # ì •í™•íˆ í•™ìŠµ ì‹œ ìˆœì„œëŒ€ë¡œ í”¼ì²˜ ìƒì„±\n",
    "            X_risk = pd.DataFrame(index=test_features.index)\n",
    "            for feat in risk_feature_names:\n",
    "                if feat in test_features.columns:\n",
    "                    X_risk[feat] = test_features[feat]\n",
    "                else:\n",
    "                    X_risk[feat] = 0.0\n",
    "        else:\n",
    "            raise ValueError(\"Risk feature names not loaded!\")\n",
    "        \n",
    "        # Predict return (r_hat) - ì•™ìƒë¸”\n",
    "        r_hat_preds = [model.predict(X_return) for model in return_models]\n",
    "        r_hat = float(np.mean([np.mean(pred) for pred in r_hat_preds]))\n",
    "        \n",
    "        # Predict risk (sigma_hat) - ì•™ìƒë¸”\n",
    "        sigma_hat_preds = [model.predict(X_risk) for model in risk_models]\n",
    "        sigma_hat = float(np.mean([np.mean(pred) for pred in sigma_hat_preds]))\n",
    "        \n",
    "        # Map to position using strategy\n",
    "        mapper = SharpeScalingMapper()\n",
    "        allocation = mapper.map_positions(\n",
    "            r_hat=np.array([r_hat]),\n",
    "            sigma_hat=np.array([sigma_hat]),\n",
    "            k=mapper_k,\n",
    "            b=mapper_b\n",
    "        )[0]\n",
    "        \n",
    "        # Ensure within bounds [0, 2]\n",
    "        allocation = max(0.0, min(2.0, float(allocation)))\n",
    "        \n",
    "        return allocation\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Prediction error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return 0.0  # Safe default\n",
    "\n",
    "print(\"âœ“ Prediction function defined!\")\n",
    "\n",
    "# ========== Start inference server ==========\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STARTING INFERENCE SERVER\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "import os\n",
    "import kaggle_evaluation.default_inference_server\n",
    "\n",
    "inference_server = kaggle_evaluation.default_inference_server.DefaultInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    # Production: Serve API for hidden test set\n",
    "    print(\"ğŸš€ Running in COMPETITION mode - serving real-time predictions\")\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    # Local testing: Run on public test set\n",
    "    print(\"ğŸ§ª Running in LOCAL mode - testing on public data\")\n",
    "    inference_server.run_local_gateway(('/kaggle/input/hull-tactical-market-prediction/',))\n",
    "\n",
    "print(\"\\nâœ… Inference server started!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
